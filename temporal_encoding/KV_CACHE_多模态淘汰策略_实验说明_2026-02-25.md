# KV Cache 多模态淘汰策略实验说明（2026-02-25）

> 适用范围：`temporal_encoding/` 下与 `test_eviction_exp_*` 相关的流式视频长上下文实验。  
> 目标：在**不微调模型**前提下，验证 Qwen2.5-VL 的 KV Cache 淘汰（sink+window）在长视频场景的工程可用性与结果真实性。

---

## 1. 本次整理后的文件结构（仅保留每个实验最有用报告）

### 脚本
- `test_eviction_exp_a.py`
- `test_eviction_exp_b.py`
- `test_eviction_exp_c.py`
- `test_eviction_exp_d_cumulative_lyrics.py`
- `test_eviction_exp_d_cumulative_lyrics_iter.py`
- `test_eviction_exp_d_trace_v2.py`
- `test_eviction_exp_abcd_realism.py`

### 报告（每类实验保留一个主报告）
- `test_eviction_exp_a_report.txt`
- `test_eviction_exp_b_report.txt`
- `test_eviction_exp_c_report.txt`
- `test_eviction_exp_d_cumulative_lyrics_report.txt`
- `test_eviction_exp_d_iter_report.txt`
- `test_eviction_exp_d_trace_report_v2.txt`
- `test_eviction_exp_abcd_realism_report.txt`

---

## 2. 总体实验链路与分工

- **A（机制正确性）**：验证自动 sink/window 与 chunk token 统计是否正确。
- **B（工程稳定性）**：验证长视频 OOM-free、cache 上限控制、淘汰确实发生。
- **C（业务能力初检）**：周期问答，检查缓存恢复与字幕抽取基本可用。
- **D（累计抽取）**：强调“截至当前时刻”的累计歌词，不只看当前帧。
- **D-iter（可量化对标）**：与参考歌词自动匹配评分。
- **D-trace-v2（可解释追踪）**：逐次提问、逐次拼接、反复读抑制全链路可观测。
- **ABCD-realism（真实性口径总评）**：覆盖率 + 顺序 + 幻觉 + 缓存恢复联合判定。

---

## 3. 各实验详细说明（思路 / 目的 / 代码实现 / 报告解读）

## 3.1 实验 A：自动参数与统计正确性

### 目的
验证淘汰器的基础参数逻辑无误，避免后续 B/C/D 结论建立在错误实现之上。

### 思路
- 先不关注任务质量，只关注机制：
  1) 首 chunk 后 sink 自动检测是否等于真实 cache 长度；
  2) window 是否等于 `max_cache_tokens - sink`；
  3) 后续 chunk 的平均 token 统计是否合理。

### 代码中如何输出到报告
- 实验头与配置：`test_eviction_exp_a.py` 第 161-167 行。  
- 每轮测试过程日志：`test_sink_detection()` 内 `report_lines` 汇总后在第 192-193 行打印。  
- 汇总段：第 197-218 行（`SUMMARY` 与最终通过提示）。

### 报告如何解读
- 看 `effective_sink_size` 与首轮 `cache_len` 是否一致。  
- 看 `window` 是否等于 `max - sink`。  
- 若 `avg_chunk_tokens` 与实际每 chunk 增量均值接近，说明统计模块可靠。

---

## 3.2 实验 B：OOM-free 与缓存平台期

### 目的
验证在 4090 24GB 环境下，长视频可持续处理且不爆显存。

### 思路
- 全视频分块编码（4 帧/chunk），持续追加。  
- 监控 `cache_len`、VRAM、eviction 次数。  
- 编码结束后再问答一次，检查 `ask()` 的 snapshot/restore 是否破坏主缓存。

### 代码中如何输出到报告
- 头部配置与预期：第 127-135 行。  
- 编码过程 chunk 级监控：第 228-234 行。  
- 编码后汇总：第 278-296 行。  
- 判定标准区：第 299-346 行（`PASS/FAIL CRITERIA`）。

### 报告如何解读
- `No OOM`：能走完整个视频即通过第一关。  
- `cache_len <= max_cache_tokens`：说明窗口裁剪有效。  
- `total_evictions > 0`：说明确实触发了淘汰而不是“假开关”。  
- `Post-ask cache == Pre-ask cache`：说明问答分支没有污染主流缓存。

---

## 3.3 实验 C：周期提问能力验证

### 目的
检查在持续淘汰下，模型是否还能稳定做“当前可见文本”识别。

### 思路
- 每隔固定 chunk 做一次问答（而非只在末尾问）。  
- 每次记录缓存长度、回答片段、TTFT、restore 是否成功。  
- 汇总所有回答并做行级去重。

### 代码中如何输出到报告
- 实验头与配置：第 130-136 行。  
- 周期性 ask 触发点：第 192-231 行。  
- 去重歌词段：第 288-293 行。  
- 总结与判定：第 297-363 行。

### 报告如何解读
- 看 `Cache restored: ✅` 的比例（应接近 100%）。  
- 看 `Unique lyric lines` 是否大于 0。  
- 看 `Average TTFT` 是否在可接受范围。

---

## 3.4 实验 D：累计歌词抽取（主流程版）

### 目的
把问题从“当前帧 OCR”提升到“截至当前时刻累计记忆”，验证流式缓存是否能承载跨时段汇总。

### 思路
- 每次问两个问题：
  - `QUESTION_CUMULATIVE`：截至当前累计看见过的歌词；
  - `QUESTION_CURRENT`：当前帧可见歌词。
- 两路答案合并，增量更新全局去重表（按首次出现时间/chunk 记录）。

### 代码中如何输出到报告
- ask 过程日志：第 268-274 行。  
- 最终去重歌词列表：第 279-285 行。  
- 分析与判定：第 287-319 行。

### 报告如何解读
- `Total unique lines`：累计抽取覆盖程度。  
- `All snapshot/restore valid`：分支问答是否安全。  
- `D1~D4`：完整链路是否满足工程与任务底线。

---

## 3.5 实验 D-iter：参考答案自动对标

### 目的
把“看起来不错”变成可量化评价：对每条标准歌词判断是否命中。

### 思路
- 预置 `REFERENCE_LINES`。  
- `evaluate()` 对每条 reference 找第一条匹配命中。  
- 输出 `match = x / N`。

### 代码中如何输出到报告
- ask 过程增量日志：第 243-245 行。  
- 去重歌词列表：第 254-259 行。  
- 对标区：第 261-272 行。  
- 结果区：第 285-289 行。

### 报告如何解读
- `MATCH AGAINST REFERENCE`：逐句命中情况。  
- `match=...%`：总体覆盖率。  
- 若低于阈值，进入 prompt/采样/频率迭代。

---

## 3.6 实验 D-trace-v2：反复读问题定位与修复追踪

### 目的
解决静态画面下模型“贪心复读”导致日志和拼接噪声的问题，并让拼接过程完全可解释。

### 思路
- 低风险解码策略：缩短输出长度 + 轻采样（不改权重）。
- 输出后清洗：`strip_generation_loop()` 去除行级循环复读。
- 轮内去重：`dedup_in_answer()` 对同轮候选先做 exact/near 去重。
- 报告中同时保留：RAW / CLEANED / dedup 前后 / merge action。

### 代码中关键实现
- 反复读抑制参数：第 28-33 行。  
- 循环输出清洗：第 58-89 行。  
- 轮内去重：第 111-129 行。  
- ask 解码参数（启用采样）：第 216-229 行。  
- 透明日志输出：第 241-261 行。

### 报告如何解读
- `RAW ... answer`：模型原始输出（可能含复读）。  
- `loop_clean_stats`：本轮清掉多少循环行。  
- `CLEANED ... answer`：清洗后文本。  
- `in_ask_stats`：轮内 exact/near 去重效果。  
- `Merge action`：哪些行被新增、哪些是重复。

---

## 3.7 ABCD-realism：真实性口径联合评估

### 目的
避免“只追高分”，引入更接近真实能力的多维指标。

### 思路
联合考察：
- 覆盖率（有没有）；
- 顺序（是否按歌词顺序）；
- 幻觉率（是否乱编）；
- 缓存恢复（是否污染主状态）。

### 代码中如何输出到报告
- A/B/C/D 四段输出：`run_exp_a/b/c/d`。  
- D 段关键指标：`coverage/order/hallucination` 在第 245-250 行打印。  
- 终判 JSON：第 279-280 行；结论第 281-284 行。

### 报告如何解读
- 只看 coverage 不够，需同时看：
  - `order_lcs`（顺序保真）
  - `hallucination`（噪声占比）
  - `restore_fail`（缓存污染风险）

---

## 4. 你最关心的问题：为什么会有“连续重复”

根因不是 KV 淘汰本身，而是**解码行为 + 场景静态性**：
- 静态字幕画面上，贪心解码容易反复输出同一句；
- `max_new_tokens` 过大时会放大这种循环；
- 同一轮里 cumulative+current 合并，会进一步放大“看起来重复很多”。

D-trace-v2 已采用“解码抑制 + 轮后清洗 + 轮内去重”三层方案解决。

---

## 5. 建议的后续使用方式

1. 日常开发：优先跑 `test_eviction_exp_d_trace_v2.py`（最可解释）。  
2. 论文/答辩：引用 `test_eviction_exp_abcd_realism_report.txt`（真实性联合指标）。  
3. 工程上线前：复跑 A/B 确保机制与显存稳定，再跑 C/D 验证业务质量。

---

## 6. 本说明对应的“本次修改”范围声明

本说明只覆盖：
- KV Cache 多模态流式淘汰实验链（A/B/C/D/D-iter/D-trace-v2/ABCD-realism）；
- 反复读修复相关代码与报告解释；
- 项目内实验文件清理（每实验保留一个主报告）。

不包含：
- Web Demo 交互层；
- 其它 `test_step*` 早期验证链路的详细解释。
