"""
æµ‹è¯•æ–°æ–¹æ¡ˆï¼šå»¶è¿Ÿæ‰¹é‡ç¼–ç  (Delayed Batch Inference)

æµ‹è¯•æµç¨‹ï¼š
1. æµå¼æ·»åŠ å¸§
2. åœ¨ä¸åŒæ—¶åˆ»æé—®
3. å¯¹æ¯”åŸç”Ÿè§†é¢‘æ¨ç†çš„ç»“æœ
4. æµ‹è¯•åŠ¨æ€é‡‡æ ·ä¸ç»å¯¹æ—¶é—´ç¼–ç 
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import torch
from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor
from PIL import Image
import time
from pathlib import Path
from typing import TextIO

from temporal_encoding.model.delayed_batch_inference import DelayedBatchInferenceEngine
from temporal_encoding.model.video_sampler import validate_time_encoding


class TeeIO:
    """å°†è¾“å‡ºåŒæ—¶å†™å…¥å¤šä¸ªæµ"""

    def __init__(self, *streams: TextIO):
        self.streams = streams

    def write(self, data: str) -> int:
        for stream in self.streams:
            stream.write(data)
        return len(data)

    def flush(self) -> None:
        for stream in self.streams:
            stream.flush()

    def isatty(self) -> bool:
        return False


def capture_test_output(log_path: Path):
    """é‡å®šå‘ stdout/stderr åˆ°æ–‡ä»¶ï¼ˆå¹¶ä¿ç•™æ§åˆ¶å°è¾“å‡ºï¼‰"""
    log_path.parent.mkdir(parents=True, exist_ok=True)
    log_file = log_path.open("w", encoding="utf-8")
    stdout_tee = TeeIO(sys.stdout, log_file)
    stderr_tee = TeeIO(sys.stderr, log_file)
    return log_file, stdout_tee, stderr_tee


def load_test_video_frames(video_source: str, max_frames: int = 50):
    """åŠ è½½æµ‹è¯•è§†é¢‘å¸§ï¼ˆæ”¯æŒå¸§ç›®å½•æˆ–è§†é¢‘æ–‡ä»¶ï¼‰"""
    source_path = Path(video_source)
    frames: list[Image.Image] = []

    if source_path.is_dir():
        frame_files = sorted(source_path.glob("*.jpg"))[:max_frames]
        for f in frame_files:
            frames.append(Image.open(f).convert("RGB"))
    elif source_path.is_file():
        try:
            import cv2
        except Exception as exc:
            raise RuntimeError("ç¼ºå°‘ OpenCVï¼Œæ— æ³•ä»è§†é¢‘æ–‡ä»¶æå–å¸§") from exc

        cap = cv2.VideoCapture(str(source_path))
        if not cap.isOpened():
            raise RuntimeError(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {source_path}")

        try:
            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            if frame_count <= 0:
                raise RuntimeError("è§†é¢‘å¸§æ•°ä¸º 0ï¼Œæ— æ³•æå–")

            if max_frames >= frame_count:
                indices = list(range(frame_count))
            else:
                step = frame_count / max_frames
                indices = [int(i * step) for i in range(max_frames)]

            for idx in indices:
                cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
                ret, frame = cap.read()
                if ret and frame is not None:
                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    frames.append(Image.fromarray(frame_rgb))
        finally:
            cap.release()
    else:
        raise RuntimeError(f"è§†é¢‘æºä¸å­˜åœ¨: {source_path}")

    print(f"âœ… åŠ è½½ {len(frames)} å¸§")
    return frames


def test_delayed_batch_inference():
    """æµ‹è¯•å»¶è¿Ÿæ‰¹é‡ç¼–ç æ–¹æ¡ˆï¼ˆå«åŠ¨æ€é‡‡æ ·ä¸ç»å¯¹æ—¶é—´ç¼–ç ï¼‰"""
    print("="*80)
    print("æµ‹è¯•ï¼šå»¶è¿Ÿæ‰¹é‡ç¼–ç æ–¹æ¡ˆ (Delayed Batch Inference)")
    print("="*80)
    
    # 1. åŠ è½½æ¨¡å‹
    model_path = "/root/autodl-tmp/Qwen/Qwen2___5-VL-3B-Instruct"
    print(f"\nğŸ“¦ åŠ è½½æ¨¡å‹: {model_path}")
    
    model = Qwen2_5_VLForConditionalGeneration.from_pretrained(
        model_path,
        torch_dtype=torch.bfloat16,
        device_map="cuda",
        trust_remote_code=True,
    )
    
    processor = AutoProcessor.from_pretrained(
        model_path,
        trust_remote_code=True,
    )
    
    # 2. åˆ›å»ºå¼•æ“ï¼ˆå¯ç”¨åŠ¨æ€é‡‡æ ·ï¼š1fps + ç¡¬ç›˜ç¼“å­˜ï¼‰
    print("\nğŸš€ åˆå§‹åŒ– DelayedBatchInferenceEngineï¼ˆå¯ç”¨ 1fps é‡‡æ · + ç»å¯¹æ—¶é—´ç¼–ç  + ç¡¬ç›˜ç¼“å­˜ï¼‰")
    engine = DelayedBatchInferenceEngine(
        model=model,
        processor=processor,
        device="cuda",
        star_memory_size=20,      # Star Memory å®¹é‡
        stream_window_size=20,    # Stream Memory çª—å£å¤§å°
        max_pixels=2 * 224 * 224, # ä½åˆ†è¾¨ç‡ç­–ç•¥
        target_fps=1.0,           # åŠ¨æ€é‡‡æ ·ï¼š1fps
        enable_absolute_time_encoding=True,  # å¯ç”¨ç»å¯¹æ—¶é—´ç¼–ç 
        use_disk_cache=True,      # å¯ç”¨ç¡¬ç›˜ç¼“å­˜ï¼ˆèŠ‚çœå†…å­˜ï¼‰
    )
    
    # 3. åŠ è½½æµ‹è¯•è§†é¢‘
    video_source = "/root/autodl-tmp/diploma/temporal_encoding/202208312002.mp4"
    frames = load_test_video_frames(video_source, max_frames=50)
    if not frames:
        raise RuntimeError("æœªåŠ è½½åˆ°ä»»ä½•å¸§ï¼Œè¯·æ£€æŸ¥è§†é¢‘æº")
    
    # 4. æµå¼æ·»åŠ å¸§ï¼ˆæ¨¡æ‹Ÿ50ç§’è§†é¢‘ï¼Œæ¯å¸§é—´éš”1ç§’ï¼‰
    print("\n" + "="*80)
    print("é˜¶æ®µ 1ï¼šæµå¼æ·»åŠ å¸§ï¼ˆæ¨¡æ‹Ÿ50ç§’è§†é¢‘ï¼‰")
    print("="*80)
    
    video_duration = 50.0  # æ¨¡æ‹Ÿ50ç§’è§†é¢‘
    frame_interval = video_duration / len(frames)
    
    for i, frame in enumerate(frames):
        timestamp = i * frame_interval
        status = engine.add_frame(frame, timestamp)
        
        # æ¯ 10 å¸§æ‰“å°ä¸€æ¬¡çŠ¶æ€
        if (i + 1) % 10 == 0:
            print(f"  [{i+1}/{len(frames)}] t={timestamp:.1f}s | {status}")
    
    print(f"\nâœ… æ‰€æœ‰å¸§å·²æ·»åŠ ï¼Œæ¨¡æ‹Ÿè§†é¢‘æ—¶é•¿: {video_duration}s")
    
    # 5. æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯
    stats = engine.get_statistics()
    print("\nğŸ“Š å¸§ç®¡ç†ç»Ÿè®¡:")
    for key, value in stats.items():
        print(f"  {key}: {value}")
    
    # 6. æé—®æµ‹è¯•ï¼ˆç¬¬ä¸€æ¬¡ä¼šè§¦å‘ç¼–ç +é‡‡æ ·ï¼‰
    print("\n" + "="*80)
    print("é˜¶æ®µ 2ï¼šæé—®æµ‹è¯•ï¼ˆè§¦å‘åŠ¨æ€é‡‡æ · + ç»å¯¹æ—¶é—´ç¼–ç ï¼‰")
    print("="*80)
    
    questions = [
        "è¯·æè¿°è§†é¢‘ä¸­çš„ä¸»è¦å†…å®¹ã€‚",
        "è§†é¢‘ä¸­æœ‰ä»€ä¹ˆäººç‰©æˆ–ç‰©ä½“ï¼Ÿ",
        "è§†é¢‘ä¸­æœ‰ä»€ä¹ˆåœºæ™¯å˜åŒ–ï¼Ÿ",
    ]
    
    for i, question in enumerate(questions, 1):
        print(f"\nâ“ é—®é¢˜ {i}: {question}")
        answer, metrics = engine.ask(question, max_new_tokens=256)
        
        print(f"ğŸ’¬ å›ç­”: {answer}")
        print(f"ğŸ“Š æŒ‡æ ‡:")
        for key, value in metrics.items():
            if 'latency' in key or 'time' in key:
                print(f"  {key}: {value:.2f}s")
            else:
                print(f"  {key}: {value}")
        
        # éªŒè¯æ—¶é—´ç¼–ç ï¼ˆä»…ç¬¬ä¸€æ¬¡æé—®æ—¶æœ‰é‡‡æ ·å…ƒæ•°æ®ï¼‰
        if i == 1 and engine.last_sample_metadata:
            meta = engine.last_sample_metadata
            print(f"\nğŸ“ é‡‡æ ·å…ƒæ•°æ®éªŒè¯:")
            print(f"  åŸå§‹å¸§æ•°: {meta['original_frames']}")
            print(f"  é‡‡æ ·åå¸§æ•°: {meta['sampled_frames']}")
            print(f"  second_per_grid_t: {meta['second_per_grid_t']:.4f}s")
            print(f"  temporal_grids: {meta['temporal_grids']}")
            # è®¡ç®—å‹ç¼©æ¯”ï¼ˆåŸå§‹å¸§æ•° / é‡‡æ ·åå¸§æ•°ï¼‰
            compression_ratio = meta['original_frames'] / meta['sampled_frames'] if meta['sampled_frames'] > 0 else 0
            print(f"  å‹ç¼©æ¯”: {compression_ratio:.2f}x")
            
            # éªŒè¯æ—¶é—´ç¼–ç è¦†ç›–
            is_valid, details = validate_time_encoding(
                sampled_frames=meta['sampled_frames'],
                second_per_grid_t=meta['second_per_grid_t'],
                expected_duration=meta['video_duration'],
                tolerance=1.0,
            )
            print(f"  æ—¶é—´ç¼–ç éªŒè¯: {'âœ… é€šè¿‡' if is_valid else 'âŒ å¤±è´¥'}")
            print(f"  è¦†ç›–æ—¶é•¿: {details['total_covered_time']:.2f}s / {details['expected_duration']:.2f}s")
    
    # 7. æµ‹è¯•å¤šæ¬¡æé—®ï¼ˆcacheå¤ç”¨ï¼‰
    print("\n" + "="*80)
    print("é˜¶æ®µ 3ï¼šCache å¤ç”¨æµ‹è¯•ï¼ˆToken Streaming è¾“å‡ºï¼‰")
    print("="*80)
    
    for i in range(3):
        print(f"\nğŸ”„ ç¬¬ {i+1} æ¬¡æé—®ï¼ˆStreaming è¾“å‡ºï¼Œåº”è¯¥å¤ç”¨ cacheï¼‰")
        question = f"è¿™æ˜¯ç¬¬ {i+1} ä¸ªé—®é¢˜ï¼Œè¯·ç®€è¦å›ç­”è§†é¢‘å†…å®¹ã€‚"
        
        t_start = time.time()
        print(f"ğŸ’¬ å›ç­”: ", end="", flush=True)
        
        # ä½¿ç”¨ streaming è¾“å‡º
        for text in engine.ask_stream(question, max_new_tokens=128):
            print(text, end="", flush=True)
        print()  # æ¢è¡Œ
        
        t_end = time.time()
        
        # è·å– metrics
        metrics = engine.last_stream_metrics
        print(f"â±ï¸  æ€»è€—æ—¶: {t_end - t_start:.2f}s")
        print(f"ğŸ“Š è¾“å‡ºtokens: {metrics.get('output_tokens', 'N/A')}")
        print(f"ğŸ“Š ç¼–ç è€—æ—¶: {metrics.get('encoding_latency', 'N/A (cacheå¤ç”¨)')}")
    
    # 8. æ·»åŠ æ–°å¸§åå†æé—®
    print("\n" + "="*80)
    print("é˜¶æ®µ 4ï¼šæ·»åŠ æ–°å¸§ + é‡æ–°ç¼–ç ")
    print("="*80)
    
    # æ·»åŠ  10 ä¸ªæ–°å¸§
    print("\nâ• æ·»åŠ  10 ä¸ªæ–°å¸§...")
    for i in range(10):
        frame = frames[i % len(frames)]  # å¤ç”¨å·²æœ‰å¸§
        timestamp = video_duration + i * 1.0  # ç»§ç»­ç´¯åŠ æ—¶é—´æˆ³
        status = engine.add_frame(frame, timestamp)
    
    print(f"\nâœ… æ–°å¸§å·²æ·»åŠ ï¼Œæ–°è§†é¢‘æ—¶é•¿: {video_duration + 10}s")
    
    # å†æ¬¡æé—®ï¼ˆä¼šè§¦å‘é‡æ–°ç¼–ç ï¼‰
    print(f"\nâ“ æ·»åŠ æ–°å¸§åæé—®:")
    question = "ç°åœ¨è§†é¢‘æœ‰æ›´æ–°ï¼Œè¯·æè¿°æœ€æ–°çš„å†…å®¹ã€‚"
    answer, metrics = engine.ask(question, max_new_tokens=256)
    
    print(f"ğŸ’¬ å›ç­”: {answer}")
    print(f"ğŸ“Š æŒ‡æ ‡:")
    for key, value in metrics.items():
        if 'latency' in key or 'time' in key:
            print(f"  {key}: {value:.2f}s")
        else:
            print(f"  {key}: {value}")
    
    # å†æ¬¡éªŒè¯æ—¶é—´ç¼–ç 
    if engine.last_sample_metadata:
        meta = engine.last_sample_metadata
        print(f"\nğŸ“ æ›´æ–°åé‡‡æ ·å…ƒæ•°æ®:")
        print(f"  é‡‡æ ·åå¸§æ•°: {meta['sampled_frames']}")
        print(f"  second_per_grid_t: {meta['second_per_grid_t']:.4f}s")
        print(f"  è§†é¢‘æ—¶é•¿: {meta['video_duration']:.2f}s")
    
    # 9. æœ€ç»ˆç»Ÿè®¡
    print("\n" + "="*80)
    print("æœ€ç»ˆç»Ÿè®¡")
    print("="*80)
    
    final_stats = engine.get_statistics()
    print(f"\nğŸ“Š æœ€ç»ˆå¸§ç®¡ç†ç»Ÿè®¡:")
    for key, value in final_stats.items():
        print(f"  {key}: {value}")
    
    print("\n" + "="*80)
    print("âœ… æµ‹è¯•å®Œæˆ!")
    print("="*80)


def test_native_vs_delayed():
    """å¯¹æ¯”åŸç”Ÿæ¨ç†ä¸å»¶è¿Ÿæ‰¹é‡ç¼–ç ï¼ˆå«åŠ¨æ€é‡‡æ ·ï¼‰"""
    print("="*80)
    print("å¯¹æ¯”æµ‹è¯•ï¼šåŸç”Ÿæ¨ç† vs å»¶è¿Ÿæ‰¹é‡ç¼–ç ï¼ˆ1fpsé‡‡æ · + ç»å¯¹æ—¶é—´ç¼–ç ï¼‰")
    print("="*80)
    
    model_path = "/root/autodl-tmp/Qwen/Qwen2___5-VL-3B-Instruct"
    
    # åŠ è½½æ¨¡å‹
    print(f"\nğŸ“¦ åŠ è½½æ¨¡å‹: {model_path}")
    model = Qwen2_5_VLForConditionalGeneration.from_pretrained(
        model_path,
        torch_dtype=torch.bfloat16,
        device_map="cuda",
        trust_remote_code=True,
    )
    
    processor = AutoProcessor.from_pretrained(
        model_path,
        trust_remote_code=True,
    )
    
    # åŠ è½½æµ‹è¯•è§†é¢‘
    video_source = "/root/autodl-tmp/diploma/temporal_encoding/202208312002.mp4"
    frames = load_test_video_frames(video_source, max_frames=30)
    if not frames:
        raise RuntimeError("æœªåŠ è½½åˆ°ä»»ä½•å¸§ï¼Œè¯·æ£€æŸ¥è§†é¢‘æº")
    
    # æ¨¡æ‹Ÿ30ç§’è§†é¢‘
    video_duration = 30.0
    question = "è¯·è¯¦ç»†æè¿°è§†é¢‘ä¸­çš„ä¸»è¦å†…å®¹å’Œåœºæ™¯ã€‚"
    
    # 1. åŸç”Ÿæ¨ç†
    print("\n" + "="*80)
    print("æ–¹æ³• 1ï¼šåŸç”Ÿè§†é¢‘æ¨ç†ï¼ˆæ— é‡‡æ ·ï¼‰")
    print("="*80)
    
    messages = [{
        "role": "user",
        "content": [
            {
                "type": "video",
                "video": frames,
                "max_pixels": 4 * 224 * 224,
            },
            {"type": "text", "text": question},
        ],
    }]
    
    text_prompt = processor.apply_chat_template(
        messages, tokenize=False, add_generation_prompt=True
    )
    
    t_start = time.time()
    inputs = processor(
        text=[text_prompt],
        videos=[frames],
        padding=True,
        return_tensors="pt",
    ).to("cuda")
    
    with torch.inference_mode():
        generated_ids = model.generate(
            **inputs,
            max_new_tokens=256,
            do_sample=True,
            temperature=0.7,
        )
    
    native_answer = processor.batch_decode(
        generated_ids,
        skip_special_tokens=True,
        clean_up_tokenization_spaces=False,
    )[0].split("assistant\n")[-1]
    
    t_end = time.time()
    native_time = t_end - t_start
    
    print(f"ğŸ’¬ åŸç”Ÿå›ç­”: {native_answer}")
    print(f"â±ï¸  è€—æ—¶: {native_time:.2f}s")
    print(f"ğŸ“ è¾“å…¥å¸§æ•°: {len(frames)}")
    
    # 2. å»¶è¿Ÿæ‰¹é‡ç¼–ç ï¼ˆå¯ç”¨1fpsé‡‡æ ·ï¼‰
    print("\n" + "="*80)
    print("æ–¹æ³• 2ï¼šå»¶è¿Ÿæ‰¹é‡ç¼–ç ï¼ˆ1fpsé‡‡æ · + ç»å¯¹æ—¶é—´ç¼–ç ï¼‰")
    print("="*80)
    
    engine = DelayedBatchInferenceEngine(
        model=model,
        processor=processor,
        device="cuda",
        star_memory_size=20,
        stream_window_size=20,
        max_pixels=2 * 224 * 224,
        target_fps=1.0,  # 1fpsé‡‡æ ·
        enable_absolute_time_encoding=True,
        use_disk_cache=True,  # å¯ç”¨ç¡¬ç›˜ç¼“å­˜
    )
    
    # æ·»åŠ æ‰€æœ‰å¸§ï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰
    frame_interval = video_duration / len(frames)
    for i, frame in enumerate(frames):
        engine.add_frame(frame, i * frame_interval)
    
    # æé—®
    t_start = time.time()
    delayed_answer, metrics = engine.ask(question, max_new_tokens=256)
    t_end = time.time()
    delayed_time = t_end - t_start
    
    print(f"ğŸ’¬ å»¶è¿Ÿç¼–ç å›ç­”: {delayed_answer}")
    print(f"â±ï¸  è€—æ—¶: {delayed_time:.2f}s")
    print(f"ğŸ“Š è¯¦ç»†æŒ‡æ ‡:")
    for key, value in metrics.items():
        if 'latency' in key or 'time' in key:
            print(f"  {key}: {value:.2f}s")
        else:
            print(f"  {key}: {value}")
    
    # æ˜¾ç¤ºé‡‡æ ·ä¿¡æ¯
    if engine.last_sample_metadata:
        meta = engine.last_sample_metadata
        print(f"\nğŸ“ é‡‡æ ·ä¿¡æ¯:")
        print(f"  åŸå§‹å¸§æ•°: {meta['original_frames']} -> é‡‡æ ·å: {meta['sampled_frames']}")
        print(f"  second_per_grid_t: {meta['second_per_grid_t']:.4f}s")
        print(f"  temporal_grids: {meta['temporal_grids']}")
        # è®¡ç®—å‹ç¼©æ¯”
        compression_ratio = meta['original_frames'] / meta['sampled_frames'] if meta['sampled_frames'] > 0 else 0
        print(f"  å‹ç¼©æ¯”: {compression_ratio:.2f}x")
        
        # éªŒè¯æ—¶é—´ç¼–ç 
        is_valid, details = validate_time_encoding(
            sampled_frames=meta['sampled_frames'],
            second_per_grid_t=meta['second_per_grid_t'],
            expected_duration=meta['video_duration'],
            tolerance=1.0,
        )
        print(f"  æ—¶é—´ç¼–ç éªŒè¯: {'âœ… é€šè¿‡' if is_valid else 'âŒ å¤±è´¥'}")
    
    # 3. ç»“æœå¯¹æ¯”
    print("\n" + "="*80)
    print("ç»“æœå¯¹æ¯”")
    print("="*80)
    
    print(f"\nåŸç”Ÿå›ç­”:\n{native_answer}\n")
    print(f"å»¶è¿Ÿç¼–ç å›ç­”:\n{delayed_answer}\n")
    
    # å¯¹æ¯”æŒ‡æ ‡
    len_ratio = len(delayed_answer) / len(native_answer) if len(native_answer) > 0 else 0
    speedup = native_time / delayed_time if delayed_time > 0 else 0
    
    print(f"ğŸ“ é•¿åº¦æ¯”: {len_ratio:.2f}")
    print(f"âš¡ é€Ÿåº¦å¯¹æ¯”: åŸç”Ÿ {native_time:.2f}s vs å»¶è¿Ÿç¼–ç  {delayed_time:.2f}s")
    print(f"   {'åŠ é€Ÿ' if speedup > 1 else 'å‡é€Ÿ'}: {abs(speedup - 1) * 100:.1f}%")
    
    print("\nâœ… å¯¹æ¯”æµ‹è¯•å®Œæˆ!")


def test_sparse_time_encoding_accuracy():
    """
    ç¨€ç–å¸§æ—¶é—´ç¼–ç ç²¾åº¦æµ‹è¯•
    
    å…³é”®æµ‹è¯•åœºæ™¯ï¼š
    - Star Memory: t=0s çš„å…³é”®å¸§
    - Stream Memory: t=50~55s çš„æœ€è¿‘å¸§
    - éªŒè¯ second_per_grid_t åæ˜ çš„æ˜¯ ~55s çš„çœŸå®æ—¶é—´è·¨åº¦ï¼Œè€Œé 5s
    
    è¿™æ˜¯éªŒè¯æ—¶é—´ç¼–ç æ­£ç¡®æ€§çš„æ ¸å¿ƒæµ‹è¯•ã€‚
    """
    print("="*80)
    print("ç¨€ç–å¸§æ—¶é—´ç¼–ç ç²¾åº¦æµ‹è¯• (Sparse Frame Time Encoding)")
    print("="*80)
    print("\nğŸ¯ æµ‹è¯•ç›®æ ‡ï¼šéªŒè¯ Star+Stream æ··åˆå¸§çš„æ—¶é—´ç¼–ç æ­£ç¡®åæ˜ çœŸå®æ—¶é—´è·¨åº¦")
    
    # ä¸éœ€è¦çœŸå®æ¨¡å‹ï¼Œåªæµ‹è¯•é‡‡æ ·é€»è¾‘
    from temporal_encoding.model.video_sampler import VideoSampler, validate_time_encoding
    from temporal_encoding.model.smart_frame_manager import SmartFrameManager
    
    # 1. åˆ›å»ºå¸§ç®¡ç†å™¨ï¼ˆä½¿ç”¨å†…å­˜æ¨¡å¼ç®€åŒ–æµ‹è¯•ï¼‰
    print("\nğŸ“¦ åˆå§‹åŒ– SmartFrameManager (å†…å­˜æ¨¡å¼)")
    frame_manager = SmartFrameManager(
        star_memory_size=10,
        stream_window_size=10,
        use_disk_cache=False,  # æµ‹è¯•ç”¨å†…å­˜æ¨¡å¼
    )
    
    # 2. æ¨¡æ‹Ÿç¨€ç–å¸§åœºæ™¯
    print("\n" + "="*80)
    print("é˜¶æ®µ 1ï¼šæ„é€ ç¨€ç–å¸§åœºæ™¯")
    print("="*80)
    
    # åˆ›å»ºæµ‹è¯•å¸§ï¼ˆç®€å•çš„çº¯è‰²å›¾åƒï¼‰
    def create_test_frame(color_value: int) -> Image.Image:
        return Image.new('RGB', (224, 224), color=(color_value, color_value, color_value))
    
    # åœºæ™¯ï¼š
    # - t=0s: é¦–å¸§ï¼ˆè‡ªåŠ¨è¿›å…¥ Star Memoryï¼‰
    # - t=50s ~ t=55s: æœ€è¿‘çš„ Stream Memory å¸§
    
    # æ·»åŠ é¦–å¸§ (t=0s) - ä¼šè¿›å…¥ Star Memory
    print(f"\nâ• æ·»åŠ é¦–å¸§ @ t=0.0s (Star Memory)")
    frame_manager.add_frame(create_test_frame(0), timestamp=0.0)
    
    # æ·»åŠ ä¸­é—´çš„ä¸€äº›å…³é”®å¸§ï¼ˆæ¨¡æ‹Ÿåœºæ™¯å˜åŒ–ï¼‰
    print(f"â• æ·»åŠ åœºæ™¯å˜åŒ–å¸§ @ t=25.0s (Star Memory)")
    # äººä¸ºåˆ¶é€ åœºæ™¯å˜åŒ–ï¼ˆå¤§å¹…åº¦é¢œè‰²å˜åŒ–ï¼‰
    frame_manager.add_frame(create_test_frame(200), timestamp=25.0)
    
    # æ·»åŠ  Stream Memory å¸§ (t=50s ~ t=55s)
    print(f"â• æ·»åŠ  Stream Memory å¸§ @ t=50.0s ~ t=55.0s")
    for i in range(6):  # 6å¸§ï¼Œt=50, 51, 52, 53, 54, 55
        t = 50.0 + i
        frame_manager.add_frame(create_test_frame(100 + i), timestamp=t)
    
    # 3. è·å–å¸§å’Œæ—¶é—´æˆ³
    print("\n" + "="*80)
    print("é˜¶æ®µ 2ï¼šè·å–å¸§å¹¶éªŒè¯æ—¶é—´æˆ³")
    print("="*80)
    
    frames, timestamps, metadata = frame_manager.get_all_frames()
    
    print(f"\nğŸ“Š å¸§ç®¡ç†å™¨çŠ¶æ€:")
    print(f"   Star Memory: {metadata['star_frames']} å¸§")
    print(f"   Stream Memory: {metadata['stream_frames']} å¸§")
    print(f"   å”¯ä¸€å¸§æ•°: {metadata['unique_frames']} å¸§")
    print(f"   æ—¶é—´è·¨åº¦: {metadata['time_span']:.2f}s (ä» t={metadata['min_timestamp']:.1f}s åˆ° t={metadata['max_timestamp']:.1f}s)")
    
    print(f"\nğŸ“‹ æ—¶é—´æˆ³åˆ—è¡¨: {timestamps}")
    
    # éªŒè¯æ—¶é—´æˆ³ç¡®å®è¦†ç›–äº†å¤§èŒƒå›´
    assert metadata['min_timestamp'] == 0.0, "æœ€å°æ—¶é—´æˆ³åº”ä¸º 0.0s"
    assert metadata['max_timestamp'] == 55.0, "æœ€å¤§æ—¶é—´æˆ³åº”ä¸º 55.0s"
    assert metadata['time_span'] == 55.0, "æ—¶é—´è·¨åº¦åº”ä¸º 55.0s"
    print(f"   âœ… æ—¶é—´æˆ³éªŒè¯é€šè¿‡")
    
    # 4. ä½¿ç”¨ sample_from_timestamps è¿›è¡Œé‡‡æ ·
    print("\n" + "="*80)
    print("é˜¶æ®µ 3ï¼šåŸºäºæ—¶é—´æˆ³é‡‡æ · (1fps)")
    print("="*80)
    
    sampler = VideoSampler(target_fps=1.0)
    sampled_frames, second_per_grid_t, sample_meta = sampler.sample_from_timestamps(
        frames=frames,
        timestamps=timestamps,
    )
    
    print(f"\nğŸ“ é‡‡æ ·ç»“æœ:")
    print(f"   åŸå§‹å¸§æ•°: {sample_meta['original_frames']}")
    print(f"   é‡‡æ ·åå¸§æ•°: {sample_meta['sampled_frames']}")
    print(f"   è§†é¢‘æ—¶é•¿: {sample_meta['video_duration']:.2f}s")
    print(f"   second_per_grid_t: {second_per_grid_t:.4f}s")
    print(f"   temporal_grids: {sample_meta['temporal_grids']}")
    
    # 5. å…³é”®éªŒè¯ï¼šsecond_per_grid_t åº”åæ˜  55s çš„æ—¶é—´è·¨åº¦
    print("\n" + "="*80)
    print("é˜¶æ®µ 4ï¼šå…³é”®éªŒè¯ - æ—¶é—´ç¼–ç ç²¾åº¦")
    print("="*80)
    
    # æ ¸å¿ƒæ–­è¨€ï¼šæ—¶é—´ç¼–ç åº”è¦†ç›– 55 ç§’
    is_valid, details = validate_time_encoding(
        sampled_frames=sample_meta['sampled_frames'],
        second_per_grid_t=second_per_grid_t,
        expected_duration=sample_meta['video_duration'],
        tolerance=1.0,
    )
    
    print(f"\nğŸ” æ—¶é—´ç¼–ç éªŒè¯:")
    print(f"   Temporal Grids: {details['num_grids']}")
    print(f"   æœ€åä¸€ä¸ª Grid æ—¶é—´: {details['last_grid_time_seconds']:.2f}s")
    print(f"   è¦†ç›–æ€»æ—¶é•¿: {details['total_covered_time']:.2f}s")
    print(f"   é¢„æœŸæ—¶é•¿: {details['expected_duration']:.2f}s")
    print(f"   æ—¶é—´è¯¯å·®: {details['time_error']:.2f}s")
    print(f"   éªŒè¯ç»“æœ: {'âœ… é€šè¿‡' if is_valid else 'âŒ å¤±è´¥'}")
    
    # å…³é”®æ–­è¨€
    assert is_valid, f"æ—¶é—´ç¼–ç éªŒè¯å¤±è´¥: {details}"
    assert sample_meta['video_duration'] >= 50.0, \
        f"video_duration åº” >= 50sï¼Œå®é™…: {sample_meta['video_duration']}"
    
    # éªŒè¯ second_per_grid_t åˆç†æ€§
    # 55ç§’è§†é¢‘ï¼Œ1fpsé‡‡æ · = ~54å¸§ï¼ˆå¯¹é½åˆ°å¶æ•°ï¼‰= 27 grids
    # second_per_grid_t â‰ˆ 55 / 27 â‰ˆ 2.03s
    expected_grids = sample_meta['sampled_frames'] // 2
    expected_second_per_grid = 55.0 / expected_grids
    
    print(f"\nğŸ“Š second_per_grid_t åˆç†æ€§æ£€æŸ¥:")
    print(f"   é¢„æœŸ grids: {expected_grids}")
    print(f"   é¢„æœŸ second_per_grid_t: {expected_second_per_grid:.4f}s")
    print(f"   å®é™… second_per_grid_t: {second_per_grid_t:.4f}s")
    
    # å…è®¸ä¸€å®šè¯¯å·®
    assert abs(second_per_grid_t - expected_second_per_grid) < 0.5, \
        f"second_per_grid_t åå·®è¿‡å¤§: é¢„æœŸ {expected_second_per_grid:.4f}s, å®é™… {second_per_grid_t:.4f}s"
    
    print(f"   âœ… éªŒè¯é€šè¿‡")
    
    # 6. å¯¹æ¯”é”™è¯¯åšæ³•ï¼ˆåŸºäºç´¢å¼•é‡‡æ ·ï¼‰
    print("\n" + "="*80)
    print("é˜¶æ®µ 5ï¼šå¯¹æ¯”æ¼”ç¤º - é”™è¯¯åšæ³• vs æ­£ç¡®åšæ³•")
    print("="*80)
    
    # é”™è¯¯åšæ³•ï¼šä½¿ç”¨ sample_framesï¼ˆåŸºäºç´¢å¼•ï¼‰
    wrong_sampler = VideoSampler(target_fps=1.0)
    _, wrong_second_per_grid, wrong_meta = wrong_sampler.sample_frames(
        frames=frames,
        original_fps=len(frames) / 55.0,  # é”™è¯¯åœ°å‡è®¾å‡åŒ€åˆ†å¸ƒ
        video_duration=55.0,
    )
    
    print(f"\nâŒ é”™è¯¯åšæ³• (sample_frames - åŸºäºç´¢å¼•):")
    print(f"   è¿™ç§æ–¹æ³•å‡è®¾å¸§æ˜¯å‡åŒ€åˆ†å¸ƒçš„ï¼Œä¼šæŠŠ t=0s å’Œ t=25s çš„å¸§")
    print(f"   å½“ä½œç›¸é‚»å¸§å¤„ç†ï¼Œå¯¼è‡´æ—¶é—´æ„ŸçŸ¥é”™ä¹±")
    print(f"   second_per_grid_t: {wrong_second_per_grid:.4f}s")
    
    print(f"\nâœ… æ­£ç¡®åšæ³• (sample_from_timestamps - åŸºäºæ—¶é—´æˆ³):")
    print(f"   è¿™ç§æ–¹æ³•å°Šé‡çœŸå®æ—¶é—´æˆ³ï¼Œæ­£ç¡®åæ˜ å¸§ä¹‹é—´çš„æ—¶é—´é—´éš”")
    print(f"   second_per_grid_t: {second_per_grid_t:.4f}s")
    
    # æœ€ç»ˆæ€»ç»“
    print("\n" + "="*80)
    print("æµ‹è¯•æ€»ç»“")
    print("="*80)
    print(f"""
ğŸ¯ æ ¸å¿ƒéªŒè¯ç‚¹:
   1. âœ… æ—¶é—´æˆ³æ­£ç¡®è¿”å› (get_all_frames è¿”å› timestamps)
   2. âœ… sample_from_timestamps æ­£ç¡®å¤„ç†ç¨€ç–å¸§
   3. âœ… second_per_grid_t åæ˜ çœŸå®æ—¶é—´è·¨åº¦ (~{second_per_grid_t:.2f}s/grid)
   4. âœ… æ¨¡å‹å°†æ„ŸçŸ¥åˆ° 55 ç§’çš„æ—¶é—´æµé€

ğŸ”‘ å…³é”®ä¿®å¤:
   - ä½¿ç”¨ sample_from_timestamps æ›¿ä»£ sample_frames
   - ç¡®ä¿ Star+Stream æ··åˆå¸§çš„æ—¶é—´ç¼–ç æ­£ç¡®
   - æ¨¡å‹ç°åœ¨èƒ½æ­£ç¡®ç†è§£"t=0s åˆ° t=55s ä¸­é—´æœ‰å¤§æ®µæ—¶é—´æµé€"
""")
    
    print("âœ… ç¨€ç–å¸§æ—¶é—´ç¼–ç æµ‹è¯•å®Œæˆ!")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="æµ‹è¯•å»¶è¿Ÿæ‰¹é‡ç¼–ç æ–¹æ¡ˆ")
    parser.add_argument(
        "--mode",
        choices=["basic", "compare", "sparse"],
        default="basic",
        help="æµ‹è¯•æ¨¡å¼ï¼šbasicï¼ˆåŸºç¡€æµ‹è¯•ï¼‰, compareï¼ˆå¯¹æ¯”æµ‹è¯•ï¼‰, sparseï¼ˆç¨€ç–å¸§æ—¶é—´ç¼–ç æµ‹è¯•ï¼‰"
    )
    
    args = parser.parse_args()

    log_path = Path(__file__).with_name("test_delayed_batch_inference_output.txt")
    log_file, stdout_tee, stderr_tee = capture_test_output(log_path)
    original_stdout = sys.stdout
    original_stderr = sys.stderr
    try:
        sys.stdout = stdout_tee
        sys.stderr = stderr_tee

        if args.mode == "basic":
            test_delayed_batch_inference()
        elif args.mode == "compare":
            test_native_vs_delayed()
        elif args.mode == "sparse":
            test_sparse_time_encoding_accuracy()
    finally:
        sys.stdout = original_stdout
        sys.stderr = original_stderr
        log_file.close()
        print(f"âœ… æµ‹è¯•è¾“å‡ºå·²ä¿å­˜åˆ°: {log_path}")
