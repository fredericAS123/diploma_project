# Copilot æ€»æ‰§è¡ŒæŒ‡ä»¤ï¼šæµå¼è§†é¢‘ç†è§£ç³»ç»Ÿå®Œæ•´æ„å»º

> **æœ€åæ›´æ–°**: 2026-02-25
> **é€‚ç”¨èŒƒå›´**: æœ¬ prompt æ˜¯ç»™ Copilot çš„ä¸€æ¬¡æ€§å®Œæ•´æ‰§è¡ŒæŒ‡ä»¤ï¼Œæ¶µç›–ä» KV Cache æ·˜æ±°éªŒè¯åˆ° VLM Agent å¯¼èˆªé—­ç¯çš„å…¨éƒ¨å·¥ä½œã€‚

---

## ã€‡ã€é¡¹ç›®èƒŒæ™¯ä¸å½“å‰çŠ¶æ€ï¼ˆä½ å¿…é¡»å…ˆç†è§£ï¼‰

### ç¡¬ä»¶ä¸æ¨¡å‹

- **GPU**: RTX 4090 24GBï¼ˆå•å¡ï¼Œä¸å¯æ›´æ¢ï¼‰
- **æ¨¡å‹**: Qwen2.5-VL-3B-Instruct (bf16)ï¼Œæ¨¡å‹æœ¬ä½“ ~7.1 GB VRAM
- **è¿è¡Œç¯å¢ƒ**: AutoDL è¿œç¨‹æœåŠ¡å™¨ï¼ŒPython 3.10+, transformers >= 4.50
- **æ¨¡å‹è·¯å¾„**: `/root/autodl-tmp/Qwen/Qwen2___5-VL-3B-Instruct`

### âš ï¸ éƒ¨ç½²æ‹“æ‰‘çº¦æŸï¼ˆæå…¶é‡è¦ï¼‰

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       HTTP API        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   æœ¬åœ° Windows æœºå™¨        â”‚  â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º  â”‚   AutoDL äº‘æœåŠ¡å™¨ (æ—  GUI)   â”‚
â”‚                           â”‚   å¸§ â†’ åŠ¨ä½œæŒ‡ä»¤       â”‚                            â”‚
â”‚  â— AirSim + Unreal Engine â”‚                       â”‚  â— Qwen2.5-VL-3B (4090)    â”‚
â”‚  â— æœ‰æ˜¾ç¤ºå™¨/GUI           â”‚                       â”‚  â— æµå¼æ¨ç†å¼•æ“ + Agent     â”‚
â”‚  â— æˆªå¸§ + æ‰§è¡Œå¯¼èˆªæŒ‡ä»¤     â”‚                       â”‚  â— FastAPI æ¨ç†æœåŠ¡         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- **AutoDL æ˜¯æ— å¤´æœåŠ¡å™¨**ï¼ˆæ—  GUIã€æ— æ˜¾ç¤ºå™¨ï¼‰ï¼Œä¸èƒ½è¿è¡Œ AirSim/Unreal Engine
- **AirSim å¿…é¡»åœ¨æœ¬åœ° Windows æœºå™¨ä¸Šè¿è¡Œ**ï¼ˆéœ€è¦ GPU æ¸²æŸ“ + æ˜¾ç¤ºå™¨ï¼‰
- ä¸¤è€…é€šè¿‡ **HTTP REST API** é€šä¿¡ï¼ˆAutoDL æä¾› FastAPI æ¨ç†æœåŠ¡ï¼Œæœ¬åœ°å‘å¸§+æ”¶æŒ‡ä»¤ï¼‰
- è¿™æ˜¯æœºå™¨äºº/å…·èº«æ™ºèƒ½ç ”ç©¶çš„**æ ‡å‡†éƒ¨ç½²æ¨¡å¼**ï¼ˆæ„ŸçŸ¥+è§„åˆ’åœ¨äº‘ç«¯ï¼Œæ‰§è¡Œåœ¨è¾¹ç«¯ï¼‰

### å·²å®Œæˆçš„æ ¸å¿ƒä»£ç ï¼ˆä¸è¦é‡å†™ï¼Œåœ¨æ­¤åŸºç¡€ä¸Šå·¥ä½œï¼‰

ä»£ç ä½äº `temporal_encoding/model/` ç›®å½•ä¸‹ï¼š

| æ–‡ä»¶ | åŠŸèƒ½ | å…³é”® API |
|------|------|---------|
| `stream_qwen_model.py` | 3-branch æµå¼ M-RoPE ä½ç½®è¿½è¸ª | `StreamQwenModel`, `stream_state`, `get_rope_index` æ‹¦æˆª |
| `cache_manager.py` | KV Cache ç”Ÿå‘½å‘¨æœŸç®¡ç† | `KVCacheManager`, `snapshot(model)`, `restore(model)`, `evict_if_needed()` |
| `video_stream_inference.py` | å®Œæ•´æµå¼æ¨ç†å¼•æ“ | `VideoStreamingInference`, `append_frame()`, `ask()`, `ask_choice()` |
| `kv_cache_eviction.py` | KV Cache æ·˜æ±°ç­–ç•¥ï¼ˆä¸‰çº§ï¼‰ | `KVCacheEvictor`, `EvictionConfig`, `TokenTypeTracker` |
| `__init__.py` | ç»Ÿä¸€å¯¼å‡º | `StreamQwenModel`, `VideoStreamingInference`, `KVCacheManager`, `EvictionConfig` |

### å…³é”®å®æµ‹æ•°æ®ï¼ˆæ¥è‡ª test_step10ï¼Œä½ çš„æ‰€æœ‰å†³ç­–å¿…é¡»åŸºäºè¿™äº›æ•°æ®ï¼‰

```
æ¨¡å‹ VRAM (bf16):           ~7.1 GB
KV cache æ¯ token:          ~36 KB (across 36 layers)
1920Ã—1080, 4å¸§/chunk:       ~5,389 tokens/chunk, ~0.185 GB/chunk
30 chunks (120å¸§):          cache 161,719 tokens, VRAM reserved 22.89 GB â†’ æé™
40 chunks (160å¸§):          OOM
å®‰å…¨ cache é¢„ç®—:             ~100,000 tokens (~3.4 GB cache)
æ¿€è¿› cache é¢„ç®—:             ~150,000 tokens (~5.2 GB cache, peak ~155K)
```

### æ¶æ„æ ¸å¿ƒè®¾è®¡

1. **Chunk-Local ViT**: ViT åªåœ¨ chunk å†…å»ºæ¨¡ï¼Œè·¨ chunk æ—¶åºç”± LLM + KV Cache + 3D-RoPE è´Ÿè´£
2. **Snapshot/Restore**: `ask()` å‰ä¿å­˜ KV Cache + `stream_state`ï¼ŒQA å®Œæˆåæ¢å¤ï¼Œé˜²æ­¢æ–‡æœ¬æ±¡æŸ“è§†é¢‘ç¼“å­˜
3. **Auto Sink Detection**: `EvictionConfig(sink_size=0)` â†’ é¦–å¸§åè‡ªåŠ¨ä»¥ cache é•¿åº¦ä½œä¸º sinkï¼ˆå› åˆ†è¾¨ç‡/å¸§æ•°ä¸åŒï¼Œä¸å¯ç¡¬ç¼–ç ï¼‰
4. **Token Tracker**: `TokenTypeTracker` è¿½è¸ªæ¯ä¸ª token çš„æ¨¡æ€ç±»å‹å’Œ chunk å½’å±ï¼Œç”¨äº Level 2/3 æ·˜æ±°

---

## ä¸€ã€å®¡é˜…è€…ä¸¥è‹›ä¿®æ”¹æ„è§ï¼ˆä½ å¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰

ä»¥ä¸‹æ˜¯æ¥è‡ªé¢†åŸŸä¸“å®¶çš„å¼ºåˆ¶æ€§ä¿®æ”¹æ„è§ï¼Œ**ä¼˜å…ˆçº§é«˜äºæ‰€æœ‰å…¶ä»–è®¾è®¡è€ƒé‡**ï¼š

### âŒ 1. ç¦æ­¢åœ¨å®æ—¶æµå¼ç³»ç»Ÿä¸­ä½¿ç”¨åŸºäºæ³¨æ„åŠ›åˆ†æ•°çš„æ·˜æ±°

**åŸå› **:
- åœ¨ 4090 ä¸Šå®æ—¶æ”¶é›†å¹¶æ’åº 36 å±‚ Transformer æ³¨æ„åŠ›çŸ©é˜µä¼šé€ æˆç¾éš¾æ€§å»¶è¿Ÿ
- Token çº§é›¶æ•£ä¸¢å¼ƒä¼šç ´å Qwen2.5-VL å±•å¹³åçš„è§†è§‰ patch ç©ºé—´ç»“æ„ï¼Œå¯¼è‡´å¹»è§‰
- LOOK-Mã€Hâ‚‚O ç­‰å·¥ä½œéƒ½æ˜¯ç¦»çº¿/ä¸€æ¬¡æ€§è¾“å…¥åœºæ™¯ï¼Œä¸é€‚ç”¨äºé«˜é¢‘è¿½åŠ çš„æµå¼ç³»ç»Ÿ

**è¡ŒåŠ¨**: 
- Level 1 (Sink + Sliding Window) æ˜¯**å”¯ä¸€éœ€è¦åœ¨å®éªŒä¸­å……åˆ†éªŒè¯**çš„æ·˜æ±°ç­–ç•¥
- Level 2 (å‡åŒ€æ—¶åºé‡‡æ ·) ä»£ç å·²æœ‰ï¼Œå¯ä½œä¸ºæ¶ˆèå®éªŒå¯¹æ¯”é¡¹ï¼Œä½†**ä¸æ˜¯ä¸»åŠ›**
- Level 3 (å¸§çº§é‡è¦æ€§) **å®Œå…¨ç æ‰**ï¼Œä¸æŠ•å…¥ä»»ä½•ç²¾åŠ›

### âŒ 2. Benchmark è¯„ä¼°ä¸åº”æˆä¸ºæ—¶é—´é»‘æ´

**åŸå› **:
- OVO-Bench/OVBench æµ‹è¯•"å›æº¯è¿‡å»"/"ç­‰å¾…æœªæ¥"çš„èƒ½åŠ›ï¼Œä½†æœ€ç»ˆè½è„šç‚¹æ˜¯æ— äººæœºå®æ—¶å¯¼èˆª
- å¯¼èˆªéœ€è¦çš„æ˜¯"å½“å‰ç©ºé—´é€šè¡Œæ€§åˆ¤æ–­å‡†ç¡®ç‡"å’Œ"å¤šæ­¥å†³ç­–è¿è´¯æ€§"ï¼Œè€Œéæ ‡å‡† VQA æŒ‡æ ‡

**è¡ŒåŠ¨**:
- OVO-Bench åªè·‘æå°è§„æ¨¡å­é›†ï¼ˆè¯æ˜æµå¼æ¶æ„ä¸äº§ç”Ÿç¾éš¾æ€§é—å¿˜å³å¯ï¼‰
- æ ¸å¿ƒè¯„ä¼°æŒ‡æ ‡æ”¹ä¸º AirSim å…·èº«æŒ‡æ ‡ï¼šç¢°æ’ç‡ã€ä»»åŠ¡æˆåŠŸç‡ã€å¹³å‡å†³ç­–å»¶è¿Ÿ

### âŒ 3. Agent æ§åˆ¶æµå¿…é¡»å¤„ç†"æ€è€ƒè€—æ—¶"

**åŸå› **:
- Qwen2.5-VL 3B ä¸€æ¬¡ 3-5 æ­¥ Agent æ¨ç†çº¦éœ€ 2-5 ç§’
- è¿™æ®µæ—¶é—´å†…æ— äººæœºç›²é£ï¼Œé‡çªå‘éšœç¢å¿…å æœº
- CodeAgent è¦æ±‚æ¨¡å‹ç”Ÿæˆ Python ä»£ç ï¼Œ7B ä»¥ä¸‹ä¸ç¨³å®šï¼Œè¯­æ³•é”™è¯¯è§¦å‘é‡è¯•æ›´æ‹‰é•¿å»¶è¿Ÿ

**è¡ŒåŠ¨**:
- Agent è¿›å…¥ `generate()` æœŸé—´ï¼Œåº•å±‚å¿…é¡»ä¸‹è¾¾ `hover()` æ‚¬åœæŒ‡ä»¤
- æ”¾å¼ƒ `CodeAgent`ï¼Œä½¿ç”¨ `ToolCallingAgent`ï¼ˆJSON ç»“æ„åŒ–è¾“å‡ºï¼Œå®¹é”™ç‡é«˜ï¼‰

### ğŸ”„ 4. æ‰§è¡Œé¡ºåºè°ƒæ•´

**åŸæ–¹æ¡ˆ**: KV Cache â†’ Benchmark â†’ Agent
**ä¿®æ”¹å**: KV Cache â†’ Agent é—­ç¯ â†’ é’ˆå¯¹æ€§è¯„ä¼°

**ç†ç”±**: å…ˆè®©æ— äººæœºé£èµ·æ¥ï¼Œæ‰èƒ½å‘ç° KV Cache å»¶è¿Ÿå¯¹é£è¡Œçš„çœŸå®å½±å“ï¼Œä»è€ŒæŒ‡å¯¼è¯„æµ‹è®¾è®¡ã€‚

---

## äºŒã€ç†è®ºé£é™©ï¼ˆPosition Gap é—®é¢˜ï¼‰

### âš ï¸ é£é™©æè¿°

æ·˜æ±° KV Cache åï¼Œä¿ç•™çš„ token å¯¹åº”çš„ Position Index ä¸å†è¿ç»­ï¼ˆå¦‚ [0..5438, 95000..100000]ï¼‰ï¼Œäº§ç”Ÿå·¨å¤§çš„ position gapã€‚åŸç”Ÿ Qwen2.5-VL **æœªé’ˆå¯¹æ­¤åœºæ™¯è®­ç»ƒ**ï¼Œå…¶ 3D-RoPE åœ¨å¤§ gap ä¸‹å¯èƒ½å¯¼è‡´ï¼š

- æ³¨æ„åŠ›åˆ†å¸ƒå¼‚å¸¸ï¼ˆattention collapseï¼‰
- å†å²å¸§ä¿¡æ¯ä¸¢å¤±ï¼Œé•¿æ—¶ä¾èµ–å»ºæ¨¡èƒ½åŠ›é€€åŒ–
- é—®ç­”/å­—å¹•æå–ç­‰ä¸‹æ¸¸ä»»åŠ¡è´¨é‡æ˜æ˜¾ä¸‹é™

### ğŸš¦ åº”å¯¹æŒ‡ä»¤

å¦‚æœåœ¨å®éªŒä¸­å‘ç°æ·˜æ±°åè´¨é‡æ˜æ˜¾ä¸‹é™ï¼Œä½ å¿…é¡»**åœ¨ä¸å¾®è°ƒæ¨¡å‹çš„å‰æä¸‹**ï¼Œä¾æ¬¡æ¢ç´¢ä»¥ä¸‹å·¥ç¨‹æ–¹æ¡ˆï¼š

1. **Position Index é‡æ˜ å°„**: æ·˜æ±°åå°†ä¿ç•™ token çš„ position è¿ç»­åŒ–ï¼ˆsink: 0..S, window: S+1..S+Wï¼‰ï¼Œæ¶ˆé™¤å¤§ gap
2. **é™ä½åˆ†è¾¨ç‡/å¸§ç‡**: å‡å°‘å•å¸§ token æ•°ï¼Œé™ä½æ·˜æ±°é¢‘ç‡ï¼Œå‡å° gap
3. **å¢å¤§ max_cache_tokens**: æƒè¡¡æ˜¾å­˜ä¸å†å²ä¿ç•™é•¿åº¦ï¼ˆ150K æ¿€è¿›å€¼ï¼‰
4. **prompt å·¥ç¨‹ / é‡‡æ ·å‚æ•°è°ƒä¼˜**: æ¸©åº¦ã€top_pã€max_new_tokens

å¦‚æ‰€æœ‰å·¥ç¨‹æ–¹æ¡ˆå‡æ— æ•ˆï¼Œæœ€åå†å»ºè®®å¾®è°ƒ/é€‚é…è®­ç»ƒã€‚

---

## ä¸‰ã€Phase 1: KV Cache æ·˜æ±°éªŒè¯ï¼ˆé¢„è®¡ 3-5 å¤©ï¼‰

### ç›®æ ‡

éªŒè¯ Level 1 (Sink + Sliding Window) åœ¨ 4090 ä¸Šèƒ½ç¨³å®šè¿è¡Œ >300 å¸§è§†é¢‘æµä¸ OOMï¼Œä¸” ask() è´¨é‡å¯æ¥å—ã€‚

### å®éªŒ A: Sink è‡ªåŠ¨æ£€æµ‹éªŒè¯

åœ¨ `temporal_encoding/` ä¸‹åˆ›å»º `test_eviction_exp_a.py`:

**éªŒè¯ç‚¹**:
1. `EvictionConfig(sink_size=0)` â†’ é¦– chunk å `effective_sink_size == cache_len`
2. ä¸åŒåˆ†è¾¨ç‡/å¸§æ•°ä¸‹ sink å€¼ä¸åŒä¸”åˆç†
3. `update_chunk_stats()` æ­£ç¡®è®°å½•å¹³å‡ token æ•°
4. `window_size` è‡ªåŠ¨è®¡ç®— = `max_cache_tokens - sink_size`

**å‚æ•°**:
- `CHUNK_FRAME_CONFIGS = [2, 4]`
- `NUM_CHUNKS = 5`ï¼ˆä¸è§¦å‘æ·˜æ±°ï¼Œä»…éªŒè¯æ£€æµ‹ï¼‰
- `MAX_CACHE_TOKENS = 100_000`

**æŠ¥å‘Š**: è¾“å‡ºåˆ° `test_eviction_exp_a_report.txt`

### å®éªŒ B: OOM-Free é•¿ç¨‹æµ‹è¯•

åˆ›å»º `test_eviction_exp_b.py`:

**éªŒè¯ç‚¹**:
1. ä½¿ç”¨ `EvictionConfig(max_cache_tokens=X)` ç¼–ç  >300 å¸§ (75+ chunks) ä¸ OOM
2. æ¯ 10 chunks è®°å½• VRAM å’Œ cache_seq_lengthï¼Œç¡®è®¤ç¨³å®š
3. æ·˜æ±°ç¡®å®è¢«è§¦å‘ï¼ˆ`total_evictions > 0`ï¼‰
4. `torch.cuda.empty_cache()` åœ¨æ·˜æ±°åè°ƒç”¨

**å‚æ•°æ‰«æ** (é€ä¸ªæµ‹è¯•ï¼Œä¸å¹¶è¡Œ):
```
max_cache_tokens = [100_000, 130_000, 150_000]
```

**æŠ¥å‘Š**: è¾“å‡ºåˆ° `test_eviction_exp_b_report.txt`

### å®éªŒ C: æ·˜æ±°å Ask è´¨é‡éªŒè¯

åˆ›å»º `test_eviction_exp_c.py`:

**éªŒè¯ç‚¹**:
1. ç¼–ç çœŸå®è§†é¢‘ï¼ˆMV/å­—å¹•è§†é¢‘ï¼‰ï¼Œæ¯ N chunks è°ƒç”¨ `ask()` æå–å­—å¹•
2. å…¨ç¨‹ä¸ OOM
3. `ask()` å cache æ­£ç¡®æ¢å¤ (snapshot/restore åœ¨æ·˜æ±°åä»å·¥ä½œ)
4. è¾“å‡ºéç©ºä¸”ä¸è§†é¢‘å†…å®¹ç›¸å…³ï¼ˆè´¨é‡ä¸å´©æºƒï¼‰

**å‚æ•°**:
- `MAX_CACHE_TOKENS = 100_000`ï¼ˆå…ˆç”¨ä¿å®ˆå€¼ï¼‰
- `ASK_INTERVAL = 20`ï¼ˆæ¯ 20 chunks æé—®ä¸€æ¬¡ï¼‰
- `QUESTION = "Read all visible text, lyrics, or subtitles on screen. Output verbatim. If no text, say 'no text'."`

**æŠ¥å‘Š**: è¾“å‡ºåˆ° `test_eviction_exp_c_report.txt`

### æ‰§è¡Œé¡ºåºä¸è¿­ä»£

```
A â†’ B â†’ C (ä¸¥æ ¼é¡ºåº)
```

æ¯ä¸ªå®éªŒå¦‚æœå¤±è´¥ï¼š
1. é˜…è¯» `_report.txt`ï¼Œç¡®è®¤å¤±è´¥æ¡ä»¶
2. æ ¹æ®å¤±è´¥ç±»å‹ä¿®æ”¹ä»£ç ï¼ˆå‚è§ä¸‹æ–¹æ–‡ä»¶å®šä½è¡¨ï¼‰
3. é‡æ–°è¿è¡ŒåŒä¸€å®éªŒç›´åˆ°é€šè¿‡
4. è¿›å…¥ä¸‹ä¸€å®éªŒ

**æ–‡ä»¶å®šä½è¡¨**:

| å¤±è´¥ç±»å‹ | å®šä½æ–‡ä»¶ | å®šä½å‡½æ•° |
|---------|---------|---------|
| sink æ£€æµ‹ä¸å¯¹ | `kv_cache_eviction.py` | `set_first_chunk_info()` |
| æ·˜æ±°æœªè§¦å‘ | `kv_cache_eviction.py` | `should_evict()` + `evict()` |
| OOM | è°ƒä½ `max_cache_tokens` / åŠ  `torch.cuda.empty_cache()` | |
| snapshot/restore å¤±è´¥ | `cache_manager.py` | `snapshot()` / `restore()` |
| è´¨é‡å´©æºƒ | è§"ç†è®ºé£é™©"ç« èŠ‚ï¼Œæ‰§è¡Œ Position é‡æ˜ å°„ç­‰æ–¹æ¡ˆ | |

---

## å››ã€Phase 2: VLM Agent å¯¼èˆªé—­ç¯ï¼ˆé¢„è®¡ 2-3 å‘¨ï¼‰

> **å®¡é˜…è€…å¼ºåˆ¶è¦æ±‚**: æœ¬é˜¶æ®µæå‰åˆ° Benchmark ä¹‹å‰ã€‚å…ˆè®©æ— äººæœºé£èµ·æ¥ã€‚
> **éƒ¨ç½²çº¦æŸ**: AutoDL æ—  GUIï¼ŒAirSim å¿…é¡»åœ¨æœ¬åœ°è¿è¡Œã€‚ä¸¤è€…é€šè¿‡ HTTP API é€šä¿¡ã€‚

### 4.0 ä¸‰ç§å¯è¡Œæ–¹æ¡ˆï¼ˆæŒ‰æ¨èç¨‹åº¦æ’åºï¼‰

| æ–¹æ¡ˆ | æ¶æ„ | ä¼˜ç‚¹ | ç¼ºç‚¹ | æ¨èåº¦ |
|------|------|------|------|-------|
| **A: API Bridgeï¼ˆå®æ—¶é—­ç¯ï¼‰** | æœ¬åœ° AirSim â†” HTTP â†” AutoDL VLM | çœŸæ­£çš„é—­ç¯æ¼”ç¤ºï¼Œå­¦æœ¯ä»·å€¼æœ€é«˜ | éœ€å¤„ç†ç½‘ç»œå»¶è¿Ÿ | â­â­â­â­â­ |
| **B: ç¦»çº¿å›æ”¾** | æœ¬åœ°å½•è§†é¢‘ â†’ ä¸Šä¼  AutoDL â†’ VLM ç¦»çº¿æ¨ç† | æœ€ç®€å•ï¼Œä¸ä¾èµ–ç½‘ç»œ | éçœŸé—­ç¯ï¼Œæ— æ³•å±•ç¤ºå®æ—¶å†³ç­– | â­â­â­ |
| **C: æœ¬åœ°å…¨éƒ¨è¿è¡Œ** | æœ¬åœ°åŒæ—¶è·‘ AirSim + VLM | é›¶ç½‘ç»œå»¶è¿Ÿ | éœ€è¦æœ¬åœ°æœ‰é«˜ç«¯ GPU (â‰¥16GB) | â­â­ |

**æ¨èè·¯çº¿**: å…ˆç”¨æ–¹æ¡ˆ B éªŒè¯ Agent é€»è¾‘ â†’ å†ç”¨æ–¹æ¡ˆ A å®ç°å®æ—¶é—­ç¯æ¼”ç¤º

---

### 4.1 æ–¹æ¡ˆ A: API Bridge å®æ—¶é—­ç¯ï¼ˆæ ¸å¿ƒæ–¹æ¡ˆï¼‰

#### æ•´ä½“æ¶æ„

```
æœ¬åœ° Windows                                    AutoDL äº‘æœåŠ¡å™¨
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AirSim Client      â”‚   POST /append_frame     â”‚ FastAPI Server             â”‚
â”‚                    â”‚ â”€â”€â”€â”€â”€â”€(å¸§ JPEG bytes)â”€â”€â”€â–º â”‚                            â”‚
â”‚ 1. æˆªå¸§            â”‚                          â”‚ 1. è§£ç å¸§                   â”‚
â”‚ 2. å‘é€å¸§åˆ°äº‘ç«¯     â”‚   POST /decide           â”‚ 2. engine.append_frame()   â”‚
â”‚ 3. è¯·æ±‚å†³ç­–        â”‚ â”€â”€â”€â”€â”€â”€(è¯·æ±‚å†³ç­–)â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚ 3. smolagents Agent æ¨ç†    â”‚
â”‚ 4. æ”¶åˆ°åŠ¨ä½œæŒ‡ä»¤     â”‚ â—„â”€â”€â”€â”€â”€(JSON åŠ¨ä½œ)â”€â”€â”€â”€â”€â”€â”€â”€ â”‚ 4. è¿”å›åŠ¨ä½œ JSON            â”‚
â”‚ 5. æ‰§è¡Œ AirSim API â”‚                          â”‚                            â”‚
â”‚ 6. é‡å¤            â”‚   GET /status             â”‚ 5. get_cache_info() ç›‘æ§    â”‚
â”‚                    â”‚ â”€â”€â”€â”€â”€â”€(çŠ¶æ€æŸ¥è¯¢)â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 4.1.1 AutoDL ç«¯ï¼šFastAPI æ¨ç†æœåŠ¡å™¨

åœ¨ AutoDL çš„ `temporal_encoding/` ä¸‹åˆ›å»º `server_api.py`:

```python
"""
æµå¼ VLM æ¨ç† API æœåŠ¡å™¨ã€‚
è¿è¡Œåœ¨ AutoDL ä¸Šï¼Œæ¥æ”¶å¸§æ•°æ®ï¼Œè¿”å› Agent å†³ç­–ã€‚

å¯åŠ¨: uvicorn server_api:app --host 0.0.0.0 --port 6006
(AutoDL é»˜è®¤å¼€æ”¾ 6006 ç«¯å£ï¼Œå¯é€šè¿‡ã€Œè‡ªå®šä¹‰æœåŠ¡ã€è·å–å…¬ç½‘åœ°å€)
"""
import io
import base64
import torch
from PIL import Image
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel

from model import StreamQwenModel, VideoStreamingInference, EvictionConfig

app = FastAPI(title="Streaming VLM Navigation API")

# â”€â”€ å…¨å±€çŠ¶æ€ â”€â”€
engine = None  # VideoStreamingInference
processor = None

class FrameRequest(BaseModel):
    """å¸§æ•°æ®è¯·æ±‚"""
    frame_b64: str            # JPEG å¸§çš„ base64 ç¼–ç 
    fps: float = 2.0
    chunk_frames: int = 1     # æœ¬æ¬¡å‘é€çš„å¸§æ•°ï¼ˆå¦‚æœæ˜¯å¤šå¸§ chunkï¼‰

class DecideRequest(BaseModel):
    """å†³ç­–è¯·æ±‚"""
    question: str = "Observe the current UAV camera view. Describe obstacles, free paths, and recommend the next navigation action (forward/left/right/hover). Be concise."
    max_new_tokens: int = 128
    temperature: float = 0.3

class DecideResponse(BaseModel):
    """å†³ç­–å“åº”"""
    action: str               # æ¨èåŠ¨ä½œ: forward/left/right/hover
    reasoning: str            # VLM åŸå§‹æ¨ç†æ–‡æœ¬
    ttft: float               # é¦– token å»¶è¿Ÿ
    cache_len: int            # å½“å‰ cache é•¿åº¦
    chunks_encoded: int       # å·²ç¼–ç  chunk æ•°

@app.on_event("startup")
def load_model():
    global engine, processor
    from transformers import AutoProcessor
    import os
    
    model_path = os.environ.get(
        "QWEN_MODEL_PATH", "/root/autodl-tmp/Qwen/Qwen2___5-VL-3B-Instruct"
    )
    
    print("Loading model...")
    model = StreamQwenModel.from_pretrained(
        model_path, torch_dtype=torch.bfloat16, device_map="cuda"
    )
    processor = AutoProcessor.from_pretrained(model_path)
    
    eviction_config = EvictionConfig(max_cache_tokens=100_000)
    engine = VideoStreamingInference(
        model, processor, device="cuda", eviction_config=eviction_config
    )
    print("Model loaded. Server ready.")

@app.post("/append_frame")
def append_frame(req: FrameRequest):
    """æ¥æ”¶ä¸€å¸§/å¤šå¸§ï¼Œè¿½åŠ åˆ°è§†é¢‘æµã€‚"""
    img_bytes = base64.b64decode(req.frame_b64)
    image = Image.open(io.BytesIO(img_bytes)).convert("RGB")
    
    result = engine.append_frame(
        image, as_video=False, fps=req.fps,
        text_content="UAV camera frame."
    )
    info = engine.get_cache_info()
    return {
        "status": "ok",
        "message": result,
        "cache_len": info["cache_seq_length"],
        "chunks": info["chunks_encoded"],
    }

@app.post("/append_chunk")
def append_chunk(req: FrameRequest):
    """æ¥æ”¶å¤šå¸§ chunkï¼ˆbase64 ç¼–ç çš„å¤šå¼  JPEG æ‹¼æ¥, ç”¨ '|||' åˆ†éš”ï¼‰ã€‚"""
    parts = req.frame_b64.split("|||")
    frames = []
    for part in parts:
        img_bytes = base64.b64decode(part.strip())
        frames.append(Image.open(io.BytesIO(img_bytes)).convert("RGB"))
    
    result = engine.append_video_chunk(frames, fps=req.fps)
    info = engine.get_cache_info()
    return {
        "status": "ok",
        "message": result,
        "cache_len": info["cache_seq_length"],
        "chunks": info["chunks_encoded"],
    }

@app.post("/decide", response_model=DecideResponse)
def decide(req: DecideRequest):
    """åŸºäºå·²ç´¯ç§¯çš„è§†é¢‘è®°å¿†ï¼Œåšä¸€æ¬¡å¯¼èˆªå†³ç­–ã€‚"""
    answer, metrics = engine.ask(
        question=req.question,
        max_new_tokens=req.max_new_tokens,
        do_sample=True,
        temperature=req.temperature,
    )
    
    # ç®€å•è§£æåŠ¨ä½œå…³é”®è¯
    answer_lower = answer.lower()
    if "left" in answer_lower:
        action = "turn_left"
    elif "right" in answer_lower:
        action = "turn_right"
    elif "forward" in answer_lower or "ahead" in answer_lower:
        action = "move_forward"
    else:
        action = "hover"
    
    info = engine.get_cache_info()
    return DecideResponse(
        action=action,
        reasoning=answer.strip(),
        ttft=metrics["ttft"],
        cache_len=info["cache_seq_length"],
        chunks_encoded=info["chunks_encoded"],
    )

@app.get("/status")
def status():
    """æŸ¥è¯¢æ¨ç†å¼•æ“çŠ¶æ€ã€‚"""
    info = engine.get_cache_info()
    vram = {}
    if torch.cuda.is_available():
        torch.cuda.synchronize()
        vram = {
            "allocated_gb": round(torch.cuda.memory_allocated() / 1e9, 3),
            "reserved_gb": round(torch.cuda.memory_reserved() / 1e9, 3),
        }
    return {"engine": info, "vram": vram}

@app.post("/reset")
def reset():
    """é‡ç½®å¼•æ“çŠ¶æ€ã€‚"""
    engine.reset()
    return {"status": "ok", "message": "Engine reset."}
```

**å¯åŠ¨æ–¹å¼**ï¼ˆAutoDL ä¸Šï¼‰:
```bash
cd /root/autodl-tmp/diploma_project/temporal_encoding
pip install fastapi uvicorn python-multipart
uvicorn server_api:app --host 0.0.0.0 --port 6006
```

**è·å–å…¬ç½‘åœ°å€**: AutoDL æ§åˆ¶å° â†’ å®¹å™¨å®ä¾‹ â†’ è‡ªå®šä¹‰æœåŠ¡ â†’ è·å–å…¬ç½‘è®¿é—®åœ°å€
ï¼ˆå½¢å¦‚ `https://u123456-6006.westX.autodl.pro`ï¼‰

#### 4.1.2 æœ¬åœ°ç«¯ï¼šAirSim å®¢æˆ·ç«¯

åœ¨æœ¬åœ° Windows æœºå™¨ä¸Šåˆ›å»º `airsim_nav_client.py`:

```python
"""
AirSim å¯¼èˆªå®¢æˆ·ç«¯ã€‚
æœ¬åœ°è¿è¡Œï¼Œè¿æ¥ AirSim + è¿œç¨‹ VLM APIã€‚

å‰ç½®æ¡ä»¶:
  1. AirSim + Unreal ç¯å¢ƒå·²åœ¨æœ¬åœ°å¯åŠ¨
  2. AutoDL ä¸Š FastAPI æœåŠ¡å·²å¯åŠ¨
  3. pip install airsim requests
"""
import time
import io
import base64
import requests
import airsim
from PIL import Image

# â”€â”€ é…ç½® â”€â”€
VLM_API_BASE = "https://u123456-6006.westX.autodl.pro"  # æ›¿æ¢ä¸ºå®é™…åœ°å€
DECISION_INTERVAL = 5.0   # æ¯ 5 ç§’å†³ç­–ä¸€æ¬¡
FLIGHT_SPEED = 2.0        # m/s
FRAME_INTERVAL = 0.5      # æ¯ 0.5 ç§’æˆªä¸€å¸§å‘ç»™ VLM

def frame_to_b64(airsim_response) -> str:
    """AirSim æˆªå¸§ â†’ base64 JPEGã€‚"""
    img = Image.frombytes("RGB",
        (airsim_response.width, airsim_response.height),
        airsim_response.image_data_uint8
    )
    # é™åˆ†è¾¨ç‡ä»¥å‡å°‘ä¼ è¾“é‡å’Œ token æ•°
    img = img.resize((640, 480))
    buf = io.BytesIO()
    img.save(buf, format="JPEG", quality=85)
    return base64.b64encode(buf.getvalue()).decode()

def send_frame(b64_frame: str):
    """å‘é€ä¸€å¸§åˆ°è¿œç¨‹ VLMã€‚"""
    resp = requests.post(f"{VLM_API_BASE}/append_frame", json={
        "frame_b64": b64_frame, "fps": 2.0
    }, timeout=30)
    return resp.json()

def request_decision() -> dict:
    """è¯·æ±‚ VLM Agent åšå¯¼èˆªå†³ç­–ã€‚"""
    resp = requests.post(f"{VLM_API_BASE}/decide", json={
        "question": (
            "You are a UAV navigation agent. Based on the accumulated video "
            "memory, observe the current scene and decide: "
            "forward / turn_left / turn_right / hover. "
            "Explain briefly why."
        ),
        "max_new_tokens": 128,
        "temperature": 0.3,
    }, timeout=60)
    return resp.json()

def execute_action(client: airsim.MultirotorClient, action: str):
    """åœ¨ AirSim ä¸­æ‰§è¡ŒåŠ¨ä½œã€‚"""
    if action == "move_forward":
        client.moveByVelocityAsync(FLIGHT_SPEED, 0, 0, duration=2).join()
    elif action == "turn_left":
        yaw = client.simGetVehiclePose().orientation
        client.rotateByYawRateAsync(-30, duration=1).join()
    elif action == "turn_right":
        client.rotateByYawRateAsync(30, duration=1).join()
    elif action == "hover":
        client.hoverAsync().join()
    print(f"  Executed: {action}")

def main():
    # è¿æ¥ AirSim
    client = airsim.MultirotorClient()
    client.confirmConnection()
    client.enableApiControl(True)
    client.armDisarm(True)
    client.takeoffAsync().join()
    print("UAV ready.")
    
    frame_count = 0
    last_decision_time = 0
    
    try:
        while True:
            # 1. æˆªå¸§
            responses = client.simGetImages([
                airsim.ImageRequest("0", airsim.ImageType.Scene, False, False)
            ])
            if not responses or responses[0].width == 0:
                time.sleep(0.1)
                continue
            
            b64 = frame_to_b64(responses[0])
            frame_count += 1
            
            # 2. å‘å¸§ç»™ VLMï¼ˆç´¯ç§¯è§†é¢‘è®°å¿†ï¼‰
            result = send_frame(b64)
            print(f"Frame {frame_count}: cache_len={result.get('cache_len', '?')}")
            
            # 3. å‘¨æœŸæ€§å†³ç­–
            now = time.time()
            if now - last_decision_time >= DECISION_INTERVAL:
                # âš ï¸ æ€è€ƒå‰æ‚¬åœ
                client.hoverAsync()
                print(f"\n--- Requesting decision (frame {frame_count}) ---")
                
                decision = request_decision()
                action = decision.get("action", "hover")
                reasoning = decision.get("reasoning", "")
                ttft = decision.get("ttft", 0)
                
                print(f"  Action: {action}")
                print(f"  Reasoning: {reasoning[:200]}")
                print(f"  TTFT: {ttft:.3f}s")
                
                execute_action(client, action)
                last_decision_time = now
            
            time.sleep(FRAME_INTERVAL)
    
    except KeyboardInterrupt:
        print("\nStopping...")
    finally:
        client.hoverAsync().join()
        client.armDisarm(False)
        client.enableApiControl(False)

if __name__ == "__main__":
    main()
```

#### 4.1.3 ç½‘ç»œå»¶è¿Ÿé¢„ç®—

```
AutoDL å…¬ç½‘å»¶è¿Ÿ (ä¸Šæµ·â†’åŒ—äº¬):     ~30-50 ms RTT
å¸§ä¼ è¾“ (640Ã—480 JPEG ~50KB):    ~20 ms
VLM append_frame:                ~200-500 ms (GPU ç¼–ç )
VLM decide (ask):                ~500-2000 ms (prefill + decode)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
å•æ¬¡å†³ç­–æ€»å»¶è¿Ÿ:                    ~1-3 ç§’
```

å¯¹äº 2-5 m/s çš„ UAV + 5 ç§’å†³ç­–é—´éš”ï¼Œè¿™å®Œå…¨å¯æ¥å—ï¼ˆå†³ç­–å‰å·²æ‚¬åœï¼‰ã€‚

---

### 4.2 æ–¹æ¡ˆ B: ç¦»çº¿å›æ”¾éªŒè¯ï¼ˆå…ˆè¡Œæ–¹æ¡ˆï¼Œç”¨äºè°ƒè¯• Agent é€»è¾‘ï¼‰

åœ¨å†™ API Bridge ä¹‹å‰ï¼Œå…ˆç”¨ç¦»çº¿å›æ”¾éªŒè¯ VLM å¯¹å¯¼èˆªåœºæ™¯çš„ç†è§£èƒ½åŠ›ï¼š

#### æ­¥éª¤

1. **æœ¬åœ°å½•åˆ¶**: åœ¨ AirSim ä¸­æ‰‹åŠ¨é£è¡Œï¼Œæ¯ 0.5 ç§’æˆªå¸§ä¿å­˜ä¸º JPEG åºåˆ—
   ```python
   # æœ¬åœ°è¿è¡Œ: record_flight.py
   for i in range(600):  # 300 ç§’
       response = client.simGetImages([...])
       img.save(f"flight_frames/{i:05d}.jpg")
       time.sleep(0.5)
   ```

2. **ä¸Šä¼ åˆ° AutoDL**: `scp -r flight_frames/ root@autodl:~/autodl-tmp/data/`

3. **AutoDL ä¸Šç¦»çº¿æ¨ç†**: é€å¸§ `append_frame()` + å‘¨æœŸæ€§ `ask()` å†³ç­–
   ```python
   # AutoDL è¿è¡Œ: offline_nav_eval.py
   for i, frame_path in enumerate(sorted(glob("flight_frames/*.jpg"))):
       frame = Image.open(frame_path)
       engine.append_frame(frame, as_video=False)
       
       if i % 10 == 0:  # æ¯ 10 å¸§å†³ç­–
           answer, _ = engine.ask("Describe the scene and suggest next action.")
           log.append({"frame": i, "decision": answer})
   ```

4. **åˆ†ææ—¥å¿—**: æ£€æŸ¥ VLM çš„åœºæ™¯æè¿°æ˜¯å¦å‡†ç¡®ã€å†³ç­–æ˜¯å¦åˆç†

**ä»·å€¼**: å³ä½¿ä¸åšå®æ—¶é—­ç¯ï¼Œç¦»çº¿å›æ”¾æ•°æ®ä¹Ÿè¶³ä»¥å†™è¿›è®ºæ–‡ä½œä¸º "VLM Agent å¯¼èˆªèƒ½åŠ›éªŒè¯"ã€‚

---

### 4.3 å®ç° StreamingVLMModelï¼ˆsmolagents é›†æˆï¼‰

åœ¨ AutoDL çš„ `temporal_encoding/model/` ä¸‹åˆ›å»º `streaming_vlm_agent.py`:

```python
from smolagents.models import Model, ChatMessage, MessageRole

class StreamingVLMModel(Model):
    """
    åŒ…è£… VideoStreamingInference ä¸º smolagents Agent æ¨¡å‹ã€‚
    
    æ ¸å¿ƒè®¾è®¡:
    - å…±äº« VLM: Agent æ¨ç†å¤ç”¨å·²åŠ è½½çš„æ¨¡å‹å’Œ KV Cache
    - è§†é¢‘è®°å¿†: Agent æ¯æ¬¡æ¨ç†éƒ½èƒ½è®¿é—®å·²ç´¯ç§¯çš„è§†é¢‘å¸§
    - Snapshot/Restore: Agent æ¨ç†ä¸æ±¡æŸ“è§†é¢‘ KV Cache
    """
    
    def __init__(self, engine, processor):
        super().__init__(
            flatten_messages_as_text=False,
            model_id="StreamingQwen2.5-VL-3B",
        )
        self.engine = engine
        self.processor = processor
    
    def generate(self, messages, stop_sequences=None, 
                 response_format=None, tools_to_call_from=None, **kwargs):
        prompt = self._messages_to_prompt(messages)
        response, metrics = self.engine.ask(
            question=prompt,
            max_new_tokens=kwargs.get("max_new_tokens", 512),
            update_state=False,
        )
        if stop_sequences:
            for seq in stop_sequences:
                if seq in response:
                    response = response[:response.index(seq)]
        return ChatMessage(role=MessageRole.ASSISTANT, content=response)
    
    def _messages_to_prompt(self, messages):
        parts = []
        for msg in messages:
            role = msg.role if hasattr(msg, 'role') else msg.get('role', 'user')
            content = msg.content if hasattr(msg, 'content') else msg.get('content', '')
            if isinstance(content, str):
                parts.append(f"[{role}]: {content}")
            elif isinstance(content, list):
                for item in content:
                    if isinstance(item, dict) and item.get('type') == 'text':
                        parts.append(f"[{role}]: {item['text']}")
        return "\n".join(parts)
```

**æ³¨æ„**: smolagents çš„ `ToolCallingAgent` åœ¨ `/decide` ç«¯ç‚¹å†…éƒ¨ä½¿ç”¨ã€‚
æœ¬åœ°å®¢æˆ·ç«¯ä¸éœ€è¦ smolagentsï¼Œåªéœ€ `requests` è°ƒç”¨ APIã€‚

### 4.4 éªŒè¯æ­¥éª¤ï¼ˆä¿®è®¢ç‰ˆï¼‰

```
Step 1: æ–¹æ¡ˆ B ç¦»çº¿å›æ”¾
  â”œâ”€â”€ æœ¬åœ° AirSim å½•åˆ¶é£è¡Œè§†é¢‘å¸§åºåˆ—
  â”œâ”€â”€ ä¸Šä¼ åˆ° AutoDL
  â”œâ”€â”€ è¿è¡Œç¦»çº¿æ¨ç†ï¼ŒéªŒè¯ VLM åœºæ™¯ç†è§£ + å†³ç­–è´¨é‡
  â””â”€â”€ ç¡®è®¤ KV Cache æ·˜æ±°åœ¨å¯¼èˆªåœºæ™¯ä¸‹æ­£å¸¸å·¥ä½œ

Step 2: æ–¹æ¡ˆ A æœåŠ¡ç«¯
  â”œâ”€â”€ AutoDL ä¸Šå¯åŠ¨ FastAPI æœåŠ¡ (server_api.py)
  â”œâ”€â”€ ç”¨ curl æˆ– Python è„šæœ¬æµ‹è¯• /append_frame + /decide
  â””â”€â”€ ç¡®è®¤å»¶è¿Ÿå¯æ¥å— (<3s å•æ¬¡å†³ç­–)

Step 3: æ–¹æ¡ˆ A å®æ—¶é—­ç¯
  â”œâ”€â”€ æœ¬åœ°å¯åŠ¨ AirSim + airsim_nav_client.py
  â”œâ”€â”€ ç®€å•åœºæ™¯ (ç©ºæ—· + éšœç¢ç‰©) æµ‹è¯•
  â”œâ”€â”€ å½•å±ï¼ˆAirSim ç”»é¢ + ç»ˆç«¯æ—¥å¿—ï¼‰
  â””â”€â”€ è¿™å°±æ˜¯ç­”è¾©æ¼”ç¤ºè§†é¢‘

Step 4: æ€§èƒ½ä¼˜åŒ– (å¦‚æœ‰éœ€è¦)
  â”œâ”€â”€ å¸§åˆ†è¾¨ç‡é™ä½ (1920â†’640) å‡å°‘ token æ•°å’Œç½‘ç»œä¼ è¾“
  â”œâ”€â”€ å¤šå¸§ chunk æ‰¹é‡å‘é€ (/append_chunk) å‡å°‘ API è°ƒç”¨æ¬¡æ•°
  â””â”€â”€ è°ƒæ•´å†³ç­–é—´éš” vs é£è¡Œé€Ÿåº¦
```

### 4.5 æ˜¾å­˜é¢„ç®—

```
æ¨¡å‹æœ¬ä½“:        ~7.1 GB
KV Cache (100K): ~3.4 GB
FastAPI å¼€é”€:    ~0.1 GB (æå°)
Agent æ¨ç†å¼€é”€:   ~0.5 GB (snapshot å…±äº«æ¨¡å‹)
å‰©ä½™å®‰å…¨ä½™é‡:     ~13 GB â†’ è¶³å¤Ÿ
```

### 4.6 æœ¬åœ°æœºå™¨è¦æ±‚

```
æœ¬åœ° Windows æœºå™¨:
  â— èƒ½è¿è¡Œ AirSim + Unreal Engine (ä»»æ„ GPU å‡å¯ï¼Œåªéœ€æ¸²æŸ“)
  â— å®‰è£…: pip install airsim requests Pillow
  â— ç½‘ç»œ: èƒ½è®¿é—® AutoDL å…¬ç½‘åœ°å€
  â— ä¸éœ€è¦ ML æ¨ç†èƒ½åŠ›
```

---

## äº”ã€Phase 3: é’ˆå¯¹æ€§è¯„ä¼°ï¼ˆé¢„è®¡ 1-2 å‘¨ï¼‰

> åœ¨ Agent é—­ç¯è·‘é€šåï¼ŒåŸºäºå®é™…è§‚å¯Ÿåˆ°çš„é—®é¢˜è®¾è®¡è¯„ä¼°ã€‚

### 5.1 å…·èº«è¯„ä¼°æŒ‡æ ‡ï¼ˆæ ¸å¿ƒï¼‰

åœ¨ AirSim ä¸­å®šä¹‰ 3 ä¸ªæ ‡å‡†åŒ–åœºæ™¯ï¼š

| åœºæ™¯ | ç¯å¢ƒ | è¯„ä¼°æŒ‡æ ‡ |
|------|------|---------|
| ç®€å•é¿éšœ | ç©ºæ—· + 5 æ£µæ ‘ | ç¢°æ’ç‡, æˆåŠŸç‡, å†³ç­–å»¶è¿Ÿ |
| èµ°å»Šç©¿è¶Š | åŸå¸‚è¡—é“ | ç¢°æ’ç‡, æˆåŠŸç‡, å†³ç­–å»¶è¿Ÿ |
| æœ‰/æ— è®°å¿†å¯¹æ¯” | åŒä¸€åœºæ™¯ | æµå¼è®°å¿† vs æ— è®°å¿† çš„ Agent å†³ç­–è´¨é‡å·®å¼‚ |

### 5.2 OVO-Bench æœ€å°å­é›†ï¼ˆè¾…åŠ©ï¼‰

- åªè·‘æ¯ç±»ä»»åŠ¡ 20-50 ä¸ªæ ·æœ¬
- ç›®çš„ï¼šè¯æ˜æµå¼è¿½åŠ ä¸äº§ç”Ÿç¾éš¾æ€§é—å¿˜
- å¯¹æ¯”ï¼šåŸç”Ÿå…¨é‡è¾“å…¥ vs æµå¼è¿½åŠ  vs æµå¼+æ·˜æ±°

### 5.3 KV Cache æ•ˆç‡åˆ†æ

| å®éªŒ | æŒ‡æ ‡ | é¢„è®¡æ—¶é—´ |
|------|------|---------|
| ä¸åŒ max_cache_tokens çš„æ˜¾å­˜æ›²çº¿ | Peak VRAM (GB) | 1 å¤© |
| æ·˜æ±°å‰å TTFT/æ¨ç†å»¶è¿Ÿ | Latency (ms) | 1 å¤© |
| é•¿ç¨‹ç¨³å®šæ€§ (>300å¸§) | æ˜¾å­˜ + TTFT æ›²çº¿ | 1 å¤© |

### 5.4 æ¶ˆèå®éªŒ

| å˜é‡ | å¯é€‰å€¼ | è§‚å¯ŸæŒ‡æ ‡ |
|------|-------|---------|
| max_cache_tokens | 100K / 130K / 150K | è´¨é‡ + æ˜¾å­˜ |
| chunk_frames | 2 / 4 | è´¨é‡ + å»¶è¿Ÿ |
| fps | 1 / 2 / 4 | è´¨é‡ |
| Level 1 vs Level 2 | sink+window vs +å‡åŒ€é‡‡æ · | è´¨é‡å¯¹æ¯” |

---

## å…­ã€æ–‡ä»¶å˜æ›´æ¸…å•

### AutoDL è¿œç¨‹æœåŠ¡å™¨ (`temporal_encoding/`)

| æ–‡ä»¶ | çŠ¶æ€ | è¯´æ˜ |
|------|------|------|
| `model/kv_cache_eviction.py` | âœ… å·²æœ‰ | Level 1 ä¸ºæ ¸å¿ƒï¼ŒLevel 2 å¯é€‰æ¶ˆèï¼ŒLevel 3 ä¸ä½¿ç”¨ |
| `model/cache_manager.py` | âœ… å·²æœ‰ | snapshot/restore + eviction é›†æˆ |
| `model/video_stream_inference.py` | âœ… å·²æœ‰ | é¦– chunk auto-detect + æ·˜æ±°è§¦å‘ |
| `model/streaming_vlm_agent.py` | ğŸ†• å¾…åˆ›å»º | StreamingVLMModel for smolagents |
| `server_api.py` | ğŸ†• å¾…åˆ›å»º | FastAPI æ¨ç†æœåŠ¡å™¨ï¼ˆæ–¹æ¡ˆ A æ ¸å¿ƒï¼‰ |
| `offline_nav_eval.py` | ğŸ†• å¾…åˆ›å»º | ç¦»çº¿å¯¼èˆªå›æ”¾éªŒè¯ï¼ˆæ–¹æ¡ˆ Bï¼‰ |
| `test_eviction_exp_a.py` | ğŸ†• å¾…åˆ›å»º | å®éªŒ A: sink æ£€æµ‹ |
| `test_eviction_exp_b.py` | ğŸ†• å¾…åˆ›å»º | å®éªŒ B: OOM-Free |
| `test_eviction_exp_c.py` | ğŸ†• å¾…åˆ›å»º | å®éªŒ C: æ·˜æ±°åè´¨é‡ |

### æœ¬åœ° Windows æœºå™¨

| æ–‡ä»¶ | çŠ¶æ€ | è¯´æ˜ |
|------|------|------|
| `airsim_nav_client.py` | ğŸ†• å¾…åˆ›å»º | AirSim æˆªå¸§ + API è°ƒç”¨ + æ‰§è¡ŒåŠ¨ä½œ |
| `record_flight.py` | ğŸ†• å¾…åˆ›å»º | AirSim é£è¡Œå½•åˆ¶ï¼ˆæ–¹æ¡ˆ B ç”¨ï¼‰ |

---

## ä¸ƒã€æ€»ä½“æ‰§è¡Œé¡ºåº

```
Phase 1 (3-5 å¤©):
  å®éªŒ A â†’ å®éªŒ B â†’ å®éªŒ C
  â†“ å¦‚æœè´¨é‡å´©æºƒ â†’ æ‰§è¡Œ Position é‡æ˜ å°„ç­‰å·¥ç¨‹æ–¹æ¡ˆ
  â†“ å…¨éƒ¨é€šè¿‡

Phase 2 (2-3 å‘¨):
  smolagents å·¥å…·é“¾éªŒè¯ â†’ StreamingVLMModel â†’ AirSim é›†æˆ â†’ æ¼”ç¤ºè§†é¢‘
  â†“ é—­ç¯è·‘é€š

Phase 3 (1-2 å‘¨):
  AirSim å…·èº«è¯„ä¼° â†’ OVO-Bench æœ€å°å­é›† â†’ KV Cache æ•ˆç‡åˆ†æ â†’ æ¶ˆèå®éªŒ
  â†“ æ•°æ®é½å…¨

Phase 4 (2-3 å‘¨):
  è®ºæ–‡æ’°å†™ + ç­”è¾© PPT
```

---

## å…«ã€å…³é”®çº¦æŸæ€»ç»“ï¼ˆçº¢çº¿ï¼Œä¸å¯è¿åï¼‰

1. **å•å¡ 4090 24GB** â€” æ‰€æœ‰æ–¹æ¡ˆå¿…é¡»åœ¨æ­¤ç¡¬ä»¶ä¸Šå¯è¿è¡Œ
2. **ä¸å¾®è°ƒæ¨¡å‹** â€” åªåšå·¥ç¨‹/æ¨ç†å±‚ä¼˜åŒ–ï¼Œä¸æ”¹æ¨¡å‹æƒé‡
3. **ä¸ä½¿ç”¨æ³¨æ„åŠ›åˆ†æ•°æ·˜æ±°** â€” Level 1 ä¸ºä¸»åŠ›ï¼Œä¸å¼•å…¥ attention computation overhead
4. **Agent æ€è€ƒæœŸå¿…é¡»æ‚¬åœ** â€” ä¸å…è®¸ç›²é£
5. **ä½¿ç”¨ ToolCallingAgent** â€” ä¸ä½¿ç”¨ CodeAgentï¼ˆ3B æ¨¡å‹ä»£ç ç”Ÿæˆä¸ç¨³å®šï¼‰
6. **æ‰€æœ‰å‚æ•°åŸºäºå®æµ‹æ•°æ®** â€” ä¸ç¡¬ç¼–ç é­”æ³•æ•°å­—ï¼Œå‚ç…§ test_step10 æ•°æ®
7. **åˆ†ä½“éƒ¨ç½²** â€” AirSim åœ¨æœ¬åœ° Windowsï¼ˆæœ‰ GUIï¼‰ï¼ŒVLM åœ¨ AutoDLï¼ˆæ—  GUIï¼‰ï¼Œé€šè¿‡ HTTP API é€šä¿¡
8. **AutoDL ç«¯å£ 6006** â€” ä½¿ç”¨ AutoDLã€Œè‡ªå®šä¹‰æœåŠ¡ã€åŠŸèƒ½æš´éœ² FastAPIï¼Œä¸è¦å°è¯•åœ¨ AutoDL ä¸Šè¿è¡Œ AirSim

---

## ä¹ã€å¼€å§‹æ‰§è¡Œ

è¯·ä» **Phase 1 å®éªŒ A** å¼€å§‹ã€‚åˆ›å»º `test_eviction_exp_a.py`ï¼ŒéªŒè¯ sink è‡ªåŠ¨æ£€æµ‹æœºåˆ¶ã€‚å®Œæˆåè¾“å‡ºæŠ¥å‘Šï¼Œæˆ‘å®¡é˜…åè¿›å…¥å®éªŒ Bã€‚
