# Temporal Encoding Streaming VLM Test Suite

å®Œæ•´çš„æµ‹è¯•æ–‡æ¡£ï¼Œç”¨äºéªŒè¯ Qwen2.5-VL æµå¼æ¨ç†ç³»ç»Ÿçš„æ­£ç¡®æ€§ä¸æ€§èƒ½ã€‚

---

## ğŸ“ æµ‹è¯•æ–‡ä»¶æ¦‚è§ˆ

### æ ¸å¿ƒé€»è¾‘æµ‹è¯•ï¼ˆæ— éœ€ GPUï¼‰
- **test_step2_cache_logic.py** - KVCacheManager çº¯é€»è¾‘æµ‹è¯•
- **test_step3_prompt.py** - Prompt è£å‰ªé€»è¾‘æµ‹è¯•

### åŠŸèƒ½æµ‹è¯•ï¼ˆéœ€è¦ GPU + æ¨¡å‹ï¼‰
- **test_step1_cache.py** - KV Cache + Stream State å¿«ç…§/æ¢å¤éš”ç¦»æµ‹è¯•
- **test_step4_choice_cache.py** - ask_choice() å¤šé€‰é¡¹ç¼“å­˜éš”ç¦»æµ‹è¯•
- **test_step5_e2e.py** - ç«¯åˆ°ç«¯å¤šå¸§æ—¶åºç†è§£æµ‹è¯•

### æ€§èƒ½ä¸å¯¹æ¯”æµ‹è¯•ï¼ˆéœ€è¦ GPU + æ¨¡å‹ + è§†é¢‘ï¼‰
- **test_step6_stream_vs_native.py** - ğŸ”¥ **æ ¸å¿ƒæµ‹è¯•**ï¼šæµå¼ vs åŸç”Ÿç¦»çº¿æ¨ç†å…¨é¢å¯¹æ¯”
- **test_step7_multi_chunk.py** - å¤šå¸§ Chunk è§„æ¨¡æ€§èƒ½æµ‹è¯•

---

## ğŸ¯ æµ‹è¯•ç›®æ ‡ä¸èŒƒå›´

### 1. ç¼“å­˜éš”ç¦»éªŒè¯
ç¡®ä¿ `ask(update_state=False)` å’Œ `ask_choice()` ä¸æ±¡æŸ“è§†é¢‘æµç¼“å­˜ã€‚

**æµ‹è¯•ç‚¹ï¼š**
- KV Cache å¿«ç…§/æ¢å¤å‰åç­¾åä¸€è‡´æ€§
- æ¨¡å‹ `stream_state` (last_cache_position, rope_deltas) æ­£ç¡®ä¿å­˜/æ¢å¤
- QA åèƒ½ç»§ç»­è¿½åŠ æ–°å¸§

**ç›¸å…³æµ‹è¯•ï¼š** test_step1, test_step4

---

### 2. KVCacheManager é€»è¾‘å®Œæ•´æ€§
éªŒè¯ç¼“å­˜ç®¡ç†å™¨çš„æ‰€æœ‰æ–¹æ³•æ­£ç¡®æ€§ï¼ˆä¸ä¾èµ–å®é™…æ¨¡å‹ï¼‰ã€‚

**æµ‹è¯•ç‚¹ï¼š**
- `snapshot()`/`restore()` - æ·±æ‹·è´ + çŠ¶æ€ä¿æŠ¤
- `clone()` - ç‹¬ç«‹ç¼“å­˜å‰¯æœ¬
- `discard_snapshot()` - å¿«ç…§ä¸¢å¼ƒ
- `build_full_attention_mask()` - Attention mask æ‹¼æ¥
- `clear()` - å†…å­˜é‡Šæ”¾
- `get_seq_length()` - åºåˆ—é•¿åº¦æŸ¥è¯¢

**ç›¸å…³æµ‹è¯•ï¼š** test_step2

---

### 3. Prompt å¤„ç†é²æ£’æ€§
éªŒè¯ `_extract_vision_segment()` å¯¹ä¸åŒ chat template ç»“æ„çš„å¤„ç†ã€‚

**æµ‹è¯•ç‚¹ï¼š**
- æ­£å¸¸ vision_start/end token åŒ…è£¹
- ç¼ºå¤± vision token çš„ fallback
- å¤šæ®µ vision ç‰‡æ®µ
- ç©º prompt

**ç›¸å…³æµ‹è¯•ï¼š** test_step3

---

### 4. ç«¯åˆ°ç«¯æ—¶åºç†è§£
éªŒè¯æ¨¡å‹èƒ½æ­£ç¡®ç†è§£è·¨å¸§æ—¶åºå…³ç³»ã€‚

**æµ‹è¯•ç‚¹ï¼š**
- å•å¸§ image æ¨¡å¼ + å¤šå¸§ video chunk æ¨¡å¼
- ä¸åŒé¢œè‰²/å½¢çŠ¶çš„å¸§åºåˆ—
- "æœ€åå‡ºç°çš„æ˜¯ä»€ä¹ˆ" ç±»å‹çš„æ—¶åºé—®ç­”

**ç›¸å…³æµ‹è¯•ï¼š** test_step5

---

### 5. ğŸ”¥ æµå¼ vs åŸç”Ÿç¦»çº¿æ¨ç†å¯¹æ¯”ï¼ˆæ ¸å¿ƒéœ€æ±‚ï¼‰

**æµ‹è¯•åœºæ™¯ï¼š**
ä½¿ç”¨çœŸå®è§†é¢‘ `/root/autodl-tmp/temporal_encoding/1.mp4` (~3s, 30fps)

**æµå¼æ¨¡å¼ï¼š**
1. æŒ‰ 4 å¸§ chunk é€æ­¥ç¼–ç è‡³ 2 ç§’
2. æš‚åœåå›ç­”é—®é¢˜
3. è®°å½•ï¼šç¼–ç æ—¶é—´ã€TTFTã€æ€» QA å»¶è¿Ÿã€VRAM ä½¿ç”¨ã€Cache å¤§å°

**åŸç”Ÿæ¨¡å¼ï¼š**
1. ä¸€æ¬¡æ€§åŠ è½½å®Œæ•´è§†é¢‘ï¼ˆåŒæ ·å‰ 2 ç§’ï¼‰+ é—®é¢˜
2. Prefill + Decode ç”Ÿæˆç­”æ¡ˆ
3. è®°å½•ï¼šPrefill æ—¶é—´ï¼ˆTTFTï¼‰ã€æ€»å»¶è¿Ÿã€VRAM ä½¿ç”¨

**å¯¹æ¯”æŒ‡æ ‡ï¼š**
- **å“åº”æ—¶é—´**ï¼šTTFTã€æ€»å»¶è¿Ÿ
- **å†…å­˜æ•ˆç‡**ï¼šVRAM allocated/reservedã€Cache memory
- **ç­”æ¡ˆè´¨é‡**ï¼šæµå¼ vs ç¦»çº¿ç­”æ¡ˆä¸€è‡´æ€§
- **é€‚ç”¨åœºæ™¯åˆ†æ**

**ç›¸å…³æµ‹è¯•ï¼š** test_step6 â­

---

### 6. Chunk è§„æ¨¡æ€§èƒ½æµ‹è¯•
å¯¹æ¯”ä¸åŒå¸§æ•° chunk çš„ç¼–ç æ€§èƒ½ã€‚

**æµ‹è¯• Chunk å¤§å°ï¼š**
- 2 å¸§ (T=1): æœ€ä½å»¶è¿Ÿï¼Œæœ€å° cache å¢é•¿
- 4 å¸§ (T=2): æ¨èé…ç½®ï¼Œå»¶è¿Ÿ/è´¨é‡å‡è¡¡
- 6 å¸§ (T=3): æ›´é«˜åå
- 3 å¸§: é temporal_patch_size å€æ•°ï¼Œè§¦å‘å¸§å¡«å……

**æµ‹é‡æŒ‡æ ‡ï¼š**
- ç¼–ç å»¶è¿Ÿ
- Cache åºåˆ—é•¿åº¦å¢é•¿
- Cache å†…å­˜å ç”¨

**ç›¸å…³æµ‹è¯•ï¼š** test_step7

---

## ğŸš€ è¿è¡ŒæŒ‡å—

### ç¯å¢ƒè¦æ±‚

**åŸºç¡€ç¯å¢ƒï¼š**
```bash
Python >= 3.8
torch >= 2.0
transformers >= 4.37.0
Pillow
opencv-python (test_step6 éœ€è¦)
```

**æ¨¡å‹ä¸æ•°æ®ï¼š**
- æ¨¡å‹è·¯å¾„ï¼š`/root/autodl-tmp/Qwen/Qwen2___5-VL-3B-Instruct`
- æµ‹è¯•è§†é¢‘ï¼š`/root/autodl-tmp/temporal_encoding/1.mp4`
- GPUï¼šæ¨è >= 8GB VRAM

**ç¯å¢ƒå˜é‡ï¼ˆå¯é€‰ï¼‰ï¼š**
```bash
export QWEN_MODEL_PATH="/your/model/path"
export VIDEO_PATH="/your/video/path"
```

---

### æµ‹è¯•åˆ†ç±»è¿è¡Œ

#### 1ï¸âƒ£ CPU é€»è¾‘æµ‹è¯•ï¼ˆæ— éœ€ GPUï¼‰
```bash
cd temporal_encoding
python test_step2_cache_logic.py
python test_step3_prompt.py
```

#### 2ï¸âƒ£ GPU åŠŸèƒ½æµ‹è¯•ï¼ˆéœ€è¦æ¨¡å‹ï¼‰
```bash
python test_step1_cache.py
python test_step4_choice_cache.py
python test_step5_e2e.py
```

#### 3ï¸âƒ£ ğŸ”¥ æ ¸å¿ƒå¯¹æ¯”æµ‹è¯•ï¼ˆéœ€è¦æ¨¡å‹ + è§†é¢‘ï¼‰
```bash
python test_step6_stream_vs_native.py
```

#### 4ï¸âƒ£ æ€§èƒ½æµ‹è¯•
```bash
python test_step7_multi_chunk.py
```

#### 5ï¸âƒ£ å®Œæ•´æµ‹è¯•å¥—ä»¶
```bash
# CPU æµ‹è¯•
python test_step2_cache_logic.py && python test_step3_prompt.py

# GPU æµ‹è¯•
python test_step1_cache.py && \
python test_step4_choice_cache.py && \
python test_step5_e2e.py && \
python test_step6_stream_vs_native.py && \
python test_step7_multi_chunk.py
```

---

## ğŸ“Š é¢„æœŸè¾“å‡ºç¤ºä¾‹

### test_step6_stream_vs_native.py è¾“å‡ºç»“æ„

```
======================================================================
ğŸ“¹ STREAMING MODE TEST
======================================================================

[1] Loading video frames (first 2.0s)...
    âœ… Loaded 60 frames (fps=30.00, total=3.00s)

[2] Initializing streaming engine...
    âœ… VRAM after model load: {'allocated': 2845.12, 'reserved': 3072.00}

[3] Streaming encoding (4-frame chunks)...
    Chunk 1/15: Chunk 0 encoded (4 frame(s), cache_len=1234)
    ...
    âœ… Encoding completed in 2.456s

[4] Asking question: 'Describe what is happening in this video.'
    âœ… Answer: A person is walking in a park...
    TTFT: 0.123s
    Total QA latency: 1.234s

======================================================================
ğŸ¬ NATIVE OFFLINE MODE TEST
======================================================================
...

======================================================================
ğŸ“Š COMPARISON REPORT
======================================================================

[Encoding Performance]
  Streaming encoding time: 2.456s
  Native prefill time:     1.234s

[QA Performance]
  Streaming TTFT:          0.123s
  Native TTFT:             1.234s
  ...
```

---

## âœ… é€šè¿‡æ ‡å‡†

### æ‰€æœ‰æµ‹è¯•
- æ—  Python è¯­æ³•é”™è¯¯
- æ— è¿è¡Œæ—¶å¼‚å¸¸ï¼ˆé™¤é¢„æœŸçš„ skipï¼‰
- å…³é”®æ–­è¨€é€šè¿‡

### test_step1 & test_step4ï¼ˆç¼“å­˜éš”ç¦»ï¼‰
- QA å‰å cache ç­¾åä¸€è‡´
- `stream_state` æ­£ç¡®æ¢å¤
- QA åèƒ½ç»§ç»­è¿½åŠ å¸§

### test_step6ï¼ˆæ ¸å¿ƒå¯¹æ¯”ï¼‰
- æµå¼ä¸åŸç”Ÿéƒ½èƒ½ç”Ÿæˆåˆç†ç­”æ¡ˆ
- VRAM è®°å½•å®Œæ•´
- TTFT å’Œæ€»å»¶è¿Ÿæ•°å€¼åˆç†
- å¯¹æ¯”æŠ¥å‘Šæ¸…æ™°å±•ç¤ºæ€§èƒ½å·®å¼‚

---

## ğŸ› æ•…éšœæ’æŸ¥

### 1. æ¨¡å‹è·¯å¾„é”™è¯¯
**ç°è±¡ï¼š** `Model not found: /root/autodl-tmp/...`

**è§£å†³ï¼š**
```bash
export QWEN_MODEL_PATH="/your/actual/model/path"
```

### 2. è§†é¢‘åŠ è½½å¤±è´¥ï¼ˆtest_step6ï¼‰
**ç°è±¡ï¼š** `Cannot open video: ...`

**è§£å†³ï¼š**
```bash
export VIDEO_PATH="/your/video/path"
# æˆ–ä¿®æ”¹è„šæœ¬ä¸­çš„ VIDEO_PATH å¸¸é‡
```

### 3. CUDA OOM
**ç°è±¡ï¼š** `CUDA out of memory`

**è§£å†³ï¼š**
- å‡å° test_step6/7 ä¸­çš„ CHUNK_SIZE
- å‡å° max_new_tokens
- ä½¿ç”¨æ›´å°çš„æ¨¡å‹æˆ– INT8 é‡åŒ–

### 4. transformers ç‰ˆæœ¬ä¸å…¼å®¹
**ç°è±¡ï¼š** `TypeError: get_rope_index() got an unexpected keyword argument`

**è§£å†³ï¼š**
```bash
pip install transformers>=4.37.0 --upgrade
```

---

## ğŸ“ æµ‹è¯•æŠ¥å‘Šæ¨¡æ¿

è¿è¡Œå®Œæ•´æµ‹è¯•åï¼Œå¯ç”ŸæˆæŠ¥å‘Šï¼š

```markdown
# Streaming VLM Test Report

## Test Environment
- GPU: NVIDIA RTX 4090
- VRAM: 24GB
- Model: Qwen2.5-VL-3B-Instruct
- Video: 1.mp4 (3s, 30fps)

## Test Results

### Cache Isolation (Step 1, 4)
âœ… PASSED - Cache and stream_state correctly protected

### E2E Understanding (Step 5)
âœ… PASSED - Model correctly identifies temporal sequence

### Streaming vs Native (Step 6)
âœ… PASSED
- Streaming TTFT: 0.123s (vs Native: 1.234s) â†’ **10x faster**
- Streaming VRAM: 4.2GB (vs Native: 5.8GB) â†’ **28% less**
- Answer quality: Comparable

### Chunk Size Comparison (Step 7)
âœ… PASSED
- 2 frames: 0.045s encode, cache +256
- 4 frames: 0.078s encode, cache +512 (recommended)
- 6 frames: 0.112s encode, cache +768

## Conclusion
æµå¼æ¨ç†åœ¨ä½å»¶è¿Ÿåœºæ™¯ä¸‹ä¼˜åŠ¿æ˜æ˜¾ï¼Œé€‚åˆå®æ—¶äº¤äº’åº”ç”¨ã€‚
```

---

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [PROJECT_STRUCTURE.md](PROJECT_STRUCTURE.md) - å®Œæ•´é¡¹ç›®ç»“æ„è¯´æ˜
- [model/stream_qwen_model.py](model/stream_qwen_model.py) - æ ¸å¿ƒæµå¼æ¨¡å‹å®ç°
- [model/video_stream_inference.py](model/video_stream_inference.py) - é«˜å±‚æ¨ç†å¼•æ“

---

**Last Updated:** 2026-02-10  
**Test Coverage:** 7 test files, 6 major test scenarios  
**Status:** âœ… All tests implemented and documented
